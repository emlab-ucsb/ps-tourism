<<<<<<< HEAD
#-- load homerange and pld data predictions, then process
=======
<<<<<<< HEAD
# dispersal_distance_lim<-1000 #let us say a limit of 1000km as the dispersal distance range...realistic?
# distance_mat<-list()
# cores<-detectCores()
# registerDoParallel(cores-1)
# for (i in 1:n_pixel){ #calculate the distance of pixel i to all (except itself and no repetition, i.e., the half of the distance matrix)
#   distance <- sqrt((biol_data[i,1]-biol_data[i+1:n_pixel,1])^2+(biol_data[i,2]-biol_data[i+1:n_pixel,2])^2)/1000
#   position <- which(distance<=dispersal_distance_lim)
#
#   if (length(position)==0){next} #in case zero data
#
#   #save i,j,distance
#   prep_data<-as.data.frame(distance[position])
#   colnames(prep_data) <- "dist"
#   prep_data$pos1<-i
#   prep_data$pos2<-position+i
#
#   distance_mat[[i]] <- prep_data
# }
# distance_mat_merged <- do.call("rbind",distance_mat)
# stopImplicitCluster()
# head(distance_mat_merged)
# dim(distance_mat_merged)
# max(distance_mat_merged$pos1)
# max(distance_mat_merged$pos2)
# #save the data then load so we do not need to run the code above
# saveRDS(distance_mat_merged, file = "/Users/ren/Documents/GitHub/tourism-mpa/data/distance_mat_merged.rds")
distance_mat_merged <- readRDS(here("data","distance_mat_merged.rds"))
dim(distance_mat_merged)
head(distance_mat_merged)
#--Complete the distance matrix by adding in the self-loop and the other part of the mirror matrix
#--the second mirror half of the matrix
distance_mat_part2 <- distance_mat_merged %>% dplyr::select(dist,pos2,pos1)
colnames(distance_mat_part2) <- c("dist","pos1","pos2")
head(distance_mat_part2)
#--the link to itself
distance_mat_part3 <- data.frame(dist = rep(0,n_pixel)) %>% mutate(pos1 = 1:n_pixel, pos2 = 1:n_pixel)
head(distance_mat_part3)
#now, combine the three datasets to complete the matrix
distance_mat_full<-rbind(distance_mat_merged,distance_mat_part2,distance_mat_part3)
dim(distance_mat_full)
##--ADD a column indicating the proportion of biomass that will move at a specific site. Use a gaussian dispersal.
sigma <- 100 #this is a single value for now. Eventually, we will have species-specific parameter
#use group_by, remove the distance column
distance_mat_full_prop <- distance_mat_full %>% group_by(pos1) %>% mutate(biom_prop = exp(-( dist^2 / (2*(sigma^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-dist) %>% as.data.table()
head(distance_mat_full_prop) #fast!
#check if correct
distance_mat_full_prop %>% filter(pos1==1) %>% summarise(sum(biom_prop)) #ok good
#ok, now that we have the distance matrix, implement biomass diffusion and larval dispersal
head(biol_data)
biom <- biol_data %>% dplyr::select(pos1,B)
head(biom)
head(biol_data)
E <- biol_data$E #we can make this dynamic. i.e., as MPA size increases, E changes.
MPAcell <- biol_data$MPA
rK<-biol_data %>% dplyr::select(pos1,r,K) %>% as.data.table()
setkey(rK,pos1)
setkey(distance_mat_full_prop,pos1)
distance_mat_full_prK<-distance_mat_full_prop[rK]
#distance_mat_full_prKE<-merge(distance_mat_full_prop,rKE, all.x=TRUE)
head(distance_mat_full_prK)
##***CHUNK*** Derive B/K per pixel and E per pixel.
#K per stock
dim(KperStockCell)
rperStock_expand <- matrix(rep(MegaData$r_fin,each=120297),nrow=120297)
dim(rperStock_expand)
rperStockCell <- rperStock_expand*KperStockCell #r*K per cell
rperCell <- rowSums(rperStockCell)/rowSums(KperStockCell)
length(rperCell)
head(rperCell)
#plot r per cell
CleanCoordmegacell_EEZ_wMPA %>% select(lon, lat, MPA) %>% mutate(rperCell=rperCell) %>%
ggplot(aes(x=lon,y=lat,fill=rperCell)) + scale_fill_viridis_c(limits = c(0, max(rperCell))) + geom_raster()
#plot E per cell
plot(MegaData$Efin_BAU1_Ray,MegaData$ExploitationRate_BAU1_Ray) #ok the formula is ER=1-E
ERperStock_expand <- matrix(rep(MegaData$ExploitationRate_BAU1_Ray,each=120297),nrow=120297)
ERperStockCell <- ERperStock_expand*KperStockCell #r*K per cell
ERperCell <- rowSums(ERperStockCell)/rowSums(KperStockCell)
CleanCoordmegacell_EEZ_wMPA %>% select(lon, lat, MPA) %>% mutate(ERperCell=ERperCell) %>%
ggplot(aes(x=lon,y=lat,fill=ERperCell)) + scale_fill_viridis_c(limits = c(0, max(ERperCell))) + geom_raster()
###CHUNK
#implement the analytic solution. THIS SPEEDS UP THE COMPUTATION
#steps
#NOTE: This is not necessary!!!
#1. K per pixel per stock per cell. K density per pixel per stock should be constant.
Cleanmegacell<-readRDS(file = "/Users/ren/Documents/GitHub/FoodProvison_SupportFiles/Code Food Provision MPA/Cleanmegacell_mollweide.rds")
ncell<-dim(Cleanmegacell)[1]
kpercell_filter<-(Cleanmegacell>0)*1 #stock extent
#kperstock
MegaData <- readRDS(file = "/Users/ren/Documents/GitHub/FoodProvison_SupportFiles/Code Food Provision MPA/MegaData_Ray.rds")
kperstock <- MegaData$Kfin
head(kperstock)
#kpercellperstock. This distributes K spatially.
kpercell_denominator<-matrix(rep(colSums(kpercell_filter)/kperstock,each=ncell),nrow=ncell)
kpercell_expand<-kpercell_filter/kpercell_denominator
colSums(kpercell_expand) #ok, looks good. the same as kperstock
#plot k per cell
head(CleanCoordmegacell_EEZ_wMPA)
CleanCoordmegacell_EEZ_wMPA %>% select(lon, lat) %>% mutate(kpercell=rowSums(kpercell_expand)) %>%
ggplot(aes(x=lon,y=lat,fill=kpercell)) + scale_fill_viridis_c()+ geom_raster()
#2. r per stock
head(MegaData)
rperstock<-MegaData$r_fin
#compute bvk
#bvk_calculated <- MegaData %>% filter(INCLUDE==1) %>% summarise(bvk_calc = 1-(ExploitationRate_BAU1_Ray/r_fin))
bvk_calculated <- MegaData %>% summarise(bvk_calc = 1-(ExploitationRate_BAU1_Ray/r_fin))
head(bvk_calculated)
dim(bvk_calculated)
#3. B0vK #revisit this. Critical parameter
#BvKperStock_expand <- matrix(rep(MegaData$BK2012,each=120297),nrow=120297)
BvKperStock_expand <- matrix(rep(bvk_calculated$bvk_calc,each=120297),nrow=120297)
biomperStockCell <- BvKperStock_expand*kpercell_expand #r*K per cell
bvk_params <- BvKperStock_expand*(kpercell_expand>0) ##use this parameter
#this contains bvk per species per cell
#we do not actually need the bvk per cell. We just need a single value as it is constant per stock.
plot(bvk_params[,1])
dim(biomperStockCell)
head(biomperStockCell)
#print the first entry:
sum(biomperStockCell[,1])
plot(biomperStockCell[,1]) #ok, this is flat. good.
#Only include the stocks that are part of our analysis.
BvKperCell <- rowSums(biomperStockCell[,which(MegaData$INCLUDE==1)])/rowSums(kpercell_expand[,which(MegaData$INCLUDE==1)])
#plot average.
CleanCoordmegacell_EEZ_wMPA %>% dplyr::select(lon, lat, MPA) %>% #mutate(BvKperCell=BvKperCell) %>%
ggplot(aes(x=lon,y=lat,fill=BvKperCell)) + scale_fill_viridis_c(limits = c(0, 1)) + geom_raster()
#4. Assume all pixels allow fishing. Evaluate change in biomass at pixel i. Our assumption is conservative given that build-up of biomass only happens inside the MPA.
#Non-mpa positions
MPAcell <- biol_data$MPA
nonMPAposition<-which(MPAcell==0)
length(nonMPAposition)
length(MPAcell)
#--explore the connectivity matrix here
#--This is the base code for generating distance_mat_full_prop
head(distance_mat_full) #the columns are: dist, pos1, pos2 (pos1 is the source)
distance_mat_full_prop <- distance_mat_full %>% group_by(pos1) %>% mutate(biom_prop = exp(-( dist^2 / (2*(sigma^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-dist) %>% as.data.table()
head(distance_mat_full_prop) #fast!
#--check if correct
distance_mat_full_prop %>% group_by(pos1) %>% summarise(checksum=sum(biom_prop)) #ok, the answer is correct.
#--add evaluate MPA here
source(here("scripts","func_evaluateMPA.R"))
##--Run only once. Subsetting the connectivity matrix. Save inside a folder then call inside the function
#--subset the stock and get the row numbers where entry == 1, then subset the connectivit matrix
run_subset_connectivitymatrix <- 0 #1 for on, 0 to switch this off
#the code below can be optimized by running this in parallel.
=======
transformed_stockdistrib %>% filter(ocean==0) #ok, they are all ocean.
#plot(transformed_stockdistrib$f_highly_mpa) # use 0.5 as threshold for highly protected MPA.
ocean_coordinates <- transformed_stockdistrib %>% select(cell_id,lon,lat,f_highly_mpa)
ocean_coordinates %>% ggplot(aes(x=lon,y=lat,fill=1)) + geom_raster()
##load EEZ file
eez_mollweide <- readRDS(file = here("data","eez_mollweide.rds"))
head(eez_mollweide)
#cell id with country names
cell_id_with_country <- left_join(ocean_coordinates,eez_mollweide,by=c("lon","lat"))
#--- load MegaData --- add biomass density
MegaData<-readRDS(here("data","MegaData_Ray.rds"))
MegaData_filtered <- MegaData %>% filter(INCLUDE==1) %>% mutate(bvk_fin = 1-(ExploitationRate_BAU1_Ray/r_fin)) %>% dplyr::select(stockid,SciName,r_fin,Kfin,bvk_fin)
#ensure no negative numbers
MegaData_filtered$bvk_fin[MegaData_filtered$bvk_fin < 0] <- 0# Set very small negative values to 0
MegaData_filtered$ID <- seq.int(nrow(MegaData_filtered)) #add ID number
head(MegaData_filtered)
tail(MegaData_filtered)
dim(MegaData_filtered)
MegaData_filtered$check_stock_id<-colnames(transformed_stockdistrib)[6:1155] #ok. This is just a check that the files are matched.
#--- load the distance matrix (source, sink, distance)
merged_dist_matrix<-readRDS(here("data","distance-library","merged_dist_matrix","merged_dist_matrix.rds"))
#convert distance from m to km
merged_dist_matrix$distance <- merged_dist_matrix$distance/1000
head(merged_dist_matrix)
##This is an old code -- Not in use
# #add MPA info: i.e., MPA_sink and MPA_source... whether sink or sources are MPAs.
# MPA_source <- transformed_stockdistrib %>% dplyr::select(cell_id,f_highly_mpa) %>% mutate(f_highly_mpa = 1*(f_highly_mpa>=0.5)) %>% dplyr::rename(source=cell_id, MPA_source=f_highly_mpa)
# MPA_sink <- MPA_source %>% dplyr::rename(sink=source, MPA_sink=MPA_source)
# merged_dist_matrix_source <- left_join(merged_dist_matrix,MPA_source,by="source")
# merged_dist_matrix_source_sink <- left_join(merged_dist_matrix_source,MPA_sink,by="sink")
# dim(merged_dist_matrix_source_sink)
# #merging data option 1
# MPA<-c(1:100000)
# ptm <- proc.time()
# merged_dist_matrix_source_sink %>% mutate(MPA_sink=replace(MPA_sink,sink %in% MPA,1)) %>% head()
# (proc.time() - ptm)/60 #check process time in minutes
#
# #merging data option 2
# dataA <- merged_dist_matrix %>% as.data.table()
# dataB <- MPA_sink %>% as.data.table()
# ptm <- proc.time()
# dataA[dataB,on="sink"]
# (proc.time() - ptm)/60 #check process time in minutes
#--load homerange and pld data predictions then process
>>>>>>> b5b4b1848f57c83f4edb119f0fc99ce7c8a91efb
pld_data <- read.csv(here("data","homerange_pld_predictions","pld_rf_predictions_final.csv")) %>% dplyr::select(species,observed_PLD,predicted_PLD) %>% dplyr::rename(SciName = species)
#-- summarize in case of duplicates
pld_data_mean <- pld_data %>% group_by(SciName) %>% summarise(mean_observed_PLD = mean(observed_PLD), sd_observed_PLD = sd(observed_PLD), mean_predicted_PLD = mean(predicted_PLD))
head(pld_data_mean)
dim(pld_data_mean)
homerange_data <- read.csv(here("data","homerange_pld_predictions","homerange_rf_predictions_10112022.csv")) %>% dplyr::select(species,observed_homerange,predicted_homerange) %>% dplyr::rename(SciName = species)
homerange_data_mean <- homerange_data %>% group_by(SciName) %>% summarise(mean_observed_homerange = mean(observed_homerange), sd_observed_homerange = sd(observed_homerange), mean_predicted_homerange = mean(predicted_homerange))
head(homerange_data_mean)
species_list <- MegaData_filtered %>% dplyr::select(SciName) %>% unique()
dim(species_list)#811 species
db_with_pld <- left_join(species_list,pld_data_mean,by="SciName")
db_with_pld_hrange <- left_join(db_with_pld,homerange_data_mean)
head(db_with_pld_hrange)
dim(db_with_pld_hrange)
db_with_pld_hrange_filtered <- db_with_pld_hrange %>% mutate(PLD = ifelse(!is.na(mean_observed_PLD),mean_observed_PLD,mean_predicted_PLD), homerange = ifelse(!is.na(mean_observed_homerange),mean_observed_homerange,mean_predicted_homerange),
complete = ifelse((PLD>0 & homerange>0),1,0))
sum(db_with_pld_hrange_filtered$complete,na.rm=T) #610 species out of 811. Check what proportion of K this is
#-- merge with the full data list
MegaData_PLD_hrange <- left_join(MegaData_filtered,db_with_pld_hrange_filtered,by="SciName")
#-- max dispersal distance limit (3 sigma larvae)
3*1.33*(max(MegaData_PLD_hrange$PLD,na.rm=T)^1.3)*sqrt(pi/2) #18K
#-- add dispersal distance limit to the megadata file
MegaData_filtered_step2 <- MegaData_PLD_hrange %>% mutate(sigma_larvae = 1.33*(PLD^1.3)*sqrt(pi/2), dispersal_distance_limit = 3*sigma_larvae, homerange_radius = sqrt(homerange/pi))
head(MegaData_filtered_step2)
#-- add the geographic range of the stock
full_stock_distrib <- transformed_stockdistrib[6:1155]
geog_range_perstock<- colSums(full_stock_distrib,na.rm=T) %>% as.data.frame()
colnames(geog_range_perstock) <- c('geog_range')
geog_range_perstock$stockid <- row.names(geog_range_perstock)
head(geog_range_perstock)
MegaData_filtered_step3 <- left_join(MegaData_filtered_step2,geog_range_perstock,by="stockid")
MegaData_filtered_step_fin <- MegaData_filtered_step3 %>% mutate(Kperpixel = Kfin/geog_range)
head(MegaData_filtered_step_fin)
sum(MegaData_filtered_step_fin$complete, na.rm = T) #898
min(MegaData_filtered_step_fin$dispersal_distance_limit,na.rm=T)
#-- Remove stocks with no intersection with existing diving as their biomass will be unaffected by placing MPAs in existing dive sites
#-- load .rdata for input files [from Kat]
load(here("data","dive","tourism_model_input.RData")) %>% head()
## Input files content:"ocean_df_with_eezs" "dives_input" "suitability_input" "suitability_input" "price_country_region_input" "price_interpolated_input"
# #!!!!!!!!!
# #remove dive sites with no biomass information
# #-- stocks with no intersection with diving can be removed as they will be unaffected by MPAs in dive areas
# filter1 <- transformed_stockdistrib %>% filter(cell_id %in% suitability_input$cell_id)
# filter2 <- filter1 %>% select(-c(cell_id,lon,lat,ocean,f_highly_mpa))
# #check if all dive sites intersect with the stocks
# dive_with_biom <- rowSums(filter2,na.rm=T)
# suitability_input$with_stock <- (dive_with_biom>0)*1
# dive_with_no_biom <- suitability_input %>% filter(with_stock==0)
# dive_with_no_biom #ok, there are 7 dive sites that have no biomass information!!! so we should remove them.
#
# #revised Kat's file
# dives_input <- dives_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# dim(dives_input)
# head(dives_input)
# suitability_input <- suitability_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# price_country_region_input <- price_country_region_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# price_interpolated_input <- price_interpolated_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
#-- identify the stock that intersects with diving, and use only those stocks in the analysis
#-- stocks with no intersection with diving can be removed as they will be unaffected by MPAs in dive areas
dim(transformed_stockdistrib)
head(transformed_stockdistrib)
filter1 <- transformed_stockdistrib %>% filter(cell_id %in% suitability_input$cell_id)
dim(filter1)#there are 1807 dive sites x 1155
filter2 <- filter1 %>% select(-c(cell_id,lon,lat,ocean,f_highly_mpa))
dim(filter2) #1807 dive sites, 1150 stocks
rowSums(filter2,na.rm=T) %>% min() #all 1807 dive pixels have at least 1 dive site
# #check if all dive sites intersect with the stocks
# dive_with_biom <- rowSums(filter2,na.rm=T) %>% as.data.frame()
# dim(dive_with_biom)
# suitability_input$with_stock<- (dive_with_biom>0)*1
# dive_with_no_biom <- suitability_input %>% filter(with_stock==0)
# dive_with_no_biom #ok, there are 7 dive sites that have no biomass information!!! so we should remove them.
#Check if stocks intersect with a dive site
mysum <-colSums(filter2,na.rm=T) %>% as.data.frame()
head(mysum)
dim(mysum)
names(mysum)[1] <- "n_pixel_intersect"
sp_intersect_dive <- cbind(stockname = rownames(mysum), mysum)
dim(sp_intersect_dive)
head(sp_intersect_dive)
sp_intersect_dive %>% filter(n_pixel_intersect==0) %>% dim() ##remove 103 stocks with no intersection with diving!
stocklist_with_diving <- sp_intersect_dive %>% filter(n_pixel_intersect>0) %>% select(stockname)#which(mysum!=0)
dim(stocklist_with_diving)#1047 stocks that intersects with dive sites
head(stocklist_with_diving)
#-- now, how about stock list with complete parameters?
stocklist_complete_params <- MegaData_filtered_step_fin %>% filter(complete==1) #which(MegaData_filtered_step_fin$complete==1)
dim(stocklist_complete_params)#898 stocks with complete params
head(stocklist_complete_params)
#-- our final stocklist will be the intersection of the two
#stocklist <- stocklist_complete_params %>% filter(stockid %in% stocklist_with_diving$stockname) %>% select(stockid) #stocklist_complete_params[stocklist_complete_params %in% stocklist_with_diving]
#stocklist <- stocklist$stockid
stocklist <- stocklist_with_diving %>% filter(stockname %in% stocklist_complete_params$stockid)
stocklist <- stocklist$stockname
length(stocklist)#813 stocks with complete information
#stocklist in numeric, since it is easy to work with numbers
head(MegaData_filtered)
stocklist_index <- MegaData_filtered %>% filter(stockid %in% stocklist) %>% select(ID)
stocklist_index <- stocklist_index$ID
#--repeat because we removed stocks, so there will be pixels with no stocks
#-- check if all dive sites have country names
dive_with_eez_details <- left_join(dives_input,ocean_df_with_eezs,by="cell_id")
head(dive_with_eez_details) #we need to fill out the eez names of some countries
##-- load EEZ file, and use this to fill out missing details from the above EEZ file
eez_mollweide <- readRDS(file = here("data","eez_mollweide.rds"))
head(eez_mollweide)
dim(eez_mollweide)
#-- There are 5 pixels with diving but with no EEZ info. This creates country details for 5 pixels with no EEZ info, all New Zealand pixels
head(ocean_coordinates)
new_zealand_add_v2 <- ocean_coordinates %>% filter(cell_id %in% c(113701, 114285, 114866, 114868, 120176)) %>% mutate(CountryCode = 95, territory1="New Zealand",iso_ter1="NZL", sovereign1="New Zealand", iso_sov1="NZL") %>%
select(CountryCode,lon,lat,territory1,iso_ter1,sovereign1,iso_sov1)
eez_mollweide <- rbind(eez_mollweide,new_zealand_add_v2)
tail(eez_mollweide)
dim(eez_mollweide)
#-- create cell id with country names
cell_id_with_country <- left_join(ocean_coordinates,eez_mollweide,by=c("lon","lat"))
head(cell_id_with_country)
dim(cell_id_with_country)
#-- add Kat's EEZ file
cell_id_with_country_kat_prime <- left_join(cell_id_with_country,ocean_df_with_eezs,by=c("cell_id","lon","lat"))
#add price data with region details, given that region info is included in price info
cell_id_with_country_kat <- left_join(cell_id_with_country_kat_prime,price_country_region_input,by="cell_id")
head(cell_id_with_country_kat)
dim(cell_id_with_country_kat)
#--view regions of the world
#ggplot(data=cell_id_with_country_kat, aes(x=lon, y=lat, color=region.y)) + geom_point()
#Use filter to include only pixels with diving
cell_id_with_country_diving_only <- cell_id_with_country_kat %>% filter(cell_id %in% dives_input$cell_id)
#-- fill out region --- for pixels with missing regions
region_library <- cell_id_with_country_diving_only %>% select(territory1,region.x,region.y) %>% filter(! is.na(territory1)) %>% unique() %>% mutate(region_fill = ifelse(is.na(region.x), region.y, region.x)) %>% select(territory1,region_fill) %>% unique() %>% group_by(territory1) %>% mutate(n=n()) %>% filter(n==1 | !is.na(region_fill)) %>% select(territory1,region_fill)
#region_library <- cell_id_with_country_diving_only %>% select(territory1,region.y) %>% filter(! is.na(territory1)) %>% unique() %>% filter(! is.na(region.y))
#region_library <- rename(region_library, region_fill=region.y)
#-- manual assignment of region for territories/countries with no region assignment
region_library <- region_library %>%
mutate(region_fill=replace(region_fill, territory1=="Alaska", "North America")) %>%
mutate(region_fill=replace(region_fill, territory1=="Albania", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Andaman and Nicobar", "South Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Antarctica", "Latin America & Caribbean")) %>%  #dive pixels nearest to latin america
mutate(region_fill=replace(region_fill, territory1=="Jersey", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Slovenia", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Romania", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Azores", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Lebanon", "Middle East & North Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Madeira", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Canary Islands", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Bahrain", "Middle East & North Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Western Sahara", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Hawaii", "East Asia & Pacific")) %>%
mutate(region_fill=replace(region_fill, territory1=="Antigua and Barbuda", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Dominica", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Aruba", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Cameroon", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Galapagos", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Chagos Archipelago", "South Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Mayotte", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Glorioso Islands", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Réunion", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Easter Island", "East Asia & Pacific"))
head(region_library)
cell_id_with_country_kat_withregion <- left_join(cell_id_with_country_diving_only,region_library, by="territory1")
head(cell_id_with_country_kat_withregion)
dim(cell_id_with_country_kat_withregion)
#check if all is well
ggplot(data=cell_id_with_country_kat_withregion, aes(x=lon, y=lat, color=region_fill)) + geom_point()
#-- PAPER STAT: fraction and absolute size of global ocean suitable for diving
dim(suitability_input) #1814 suitable dive sites
dim(suitability_input)[1]*100/dim(transformed_stockdistrib)[1] #1.21% - fraction of ocean with diving.
dim(suitability_input)[1]*50*50# 4.5 million km - total area of ocean surface with diving
#-- check dives_input
head(dives_input)
dim(dives_input)#1814x4, number of dives and lower and upper bound
sum(dives_input$n_dives_extrap)#33.1 million, average number of dives in the ocean
sum(dives_input$n_dives_extrap_min)#17.1 million lower, lower bound
sum(dives_input$n_dives_extrap_max)#54 million max, upper bound
#-- check price
head(price_constant_input)
cons_price_per_dive <- price_constant_input$price[1]
cons_price_per_dive #constant price per dive of US$58.75
#-- annual revenue in billion US$
sum(dives_input$n_dives_extrap)*cons_price_per_dive/1e9 #1.94B
#lower bound annual revenue
sum(dives_input$n_dives_extrap_min)*cons_price_per_dive/1e9 #1B
#upper bound unnual revenue
sum(dives_input$n_dives_extrap_max)*cons_price_per_dive/1e9 #3.17B
#-- check other prices
head(price_country_region_input)
plot(price_country_region_input$price)
head(price_interpolated_input)
plot(price_interpolated_input$price)
#-- how many species?
#length(unique(MegaData_filtered_step_fin[stocklist,]$SciName))#599 species
MegaData_filtered_step_fin %>% filter(stockid %in% stocklist) %>% select(SciName) %>% unique() %>% dim() #599 species
#-- %K considered
#MegaData_filtered_step_fin[stocklist,] %>% dplyr::summarize(sum(Kfin))/sum(MegaData_PLD_hrange$Kfin) #we will use 74% of the K.
MegaData_filtered_step_fin %>% filter(stockid %in% stocklist) %>% dplyr::summarize(sum(Kfin))/sum(MegaData_PLD_hrange$Kfin) #we will use 74% of the K.
#-- check final list of dataset
#Checkme <- MegaData_filtered_step_fin[stocklist,]
Checkme <- MegaData_filtered_step_fin %>% filter(stockid %in% stocklist)
ggplot(Checkme, aes(x=mean_observed_PLD, y= mean_predicted_PLD)) + geom_point() + geom_abline(slope=1, intercept=0)
# #NOTE-- JUST OPEN THIS WHEN THE DISTANCE MATRICES CHANGE
# #check if we can load individual files here then merge
# #distmat_filenames <- list.files(path=here("data","distance-library","fst_file"), pattern=".fst", all.files=FALSE,full.names=TRUE)
# distmat_filenames <- list.files(path=here("data","distance-library"), pattern=".rds", all.files=FALSE,full.names=TRUE)
# distmat_filenames[1]
# length(distmat_filenames)#40 files
#
# #let us load all the distance matrices, subset, then save as fst file.
# for (i in 1:length(distmat_filenames)){
#   myfile <- readRDS(distmat_filenames[i]) %>% filter(distance<=3667657.8)
#   write.fst(myfile , here("data","distance-library","dist_matrix_subset_fst",paste0(i,"_connect_matrix.fst")))
# }
##-- Connectivity matrix, larvae
#-- no need to run, so we will switch this function off
run_subset_connectivitymatrix <- 0 #1 for turn on, 0 to switch off
#Subset larvae connectivity matrix
if(run_subset_connectivitymatrix == 1){
distmat_filenames_subset_fst <- list.files(path=here("data","distance-library","dist_matrix_subset_fst"), pattern=".fst", all.files=FALSE,full.names=TRUE)
distmat_filenames_subset_fst[1]
length(distmat_filenames_subset_fst)#40 files
source(here("scripts", "functions","func_stitch_connect_matrix.R"))
<<<<<<< HEAD
=======
#parallel version
>>>>>>> 276b6a98f17342aa5307967b1121c88b774461ab
if(run_subset_connectivitymatrix == 1){
>>>>>>> b5b4b1848f57c83f4edb119f0fc99ce7c8a91efb
stocklist2 <- c(461,467,473,475,478,stocklist[393:821])
nstock<-length(stocklist2)
registerDoParallel(6)
#stocklist2 <- 10#stocklist[10:nstock]
#registerDoParallel(detectCores()/2)
foreach(stock_num=stocklist2) %dopar% {
stock_subset_i <- which(transformed_stockdistrib[,stock_num+5] > 0)
##--! this is the code that can be used when the maximum disperal is over 1K km.
distance_mat_full_prop_larvae <- func_stitch_connect_matrix(distmat_files=distmat_filenames_subset_fst,stock_subset_i=stock_subset_i,MegaData_filtered_step2=MegaData_filtered_step2,stock_num=stock_num)
##-- merged_dist_matrix is in km
#distance_mat_full_prop_larvae <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$dispersal_distance_limit[stock_num]) %>% group_by(source) %>% mutate(biom_prop = exp(-( distance^2 / (2*(MegaData_filtered_step2$sigma_larvae[stock_num]^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-distance) %>% as.data.table()
#fts is the fastest in saving and loading files.
fst::write.fst(distance_mat_full_prop_larvae , paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/",stock_num,"_connect_larvae.fst"))
}
doParallel::stopImplicitCluster()
}
# #check how many files
# connect_matrix_nfiles <- list.files(path="/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/", pattern=".fst", all.files=FALSE,full.names=TRUE)
# length(connect_matrix_nfiles)#821 files
# for (i in 1:length(connect_matrix_nfiles)){
#   check<-read.fst(connect_matrix_nfiles[i])
#   print(dim(check)[1])
# }
##check the output
#seeme <- read.fst("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/1_connect_larvae.fst")
#seeme %>% group_by(source) %>% summarize(sum(biom_prop))
#seeme %>% group_by(sink) %>% summarize(sum(biom_prop))
##-- Connectivity matrix, adult
#-- no need to re-run so we will turn this function off
run_subset_connectivitymatrix_adult <- 0 #1 for on, 0 to switch this off
if(run_subset_connectivitymatrix_adult == 1){
registerDoParallel(detectCores()/2)
<<<<<<< HEAD
#CHECK IF THIS IS CORRECT: which(MegaData$INCLUDE==1)
foreach(stock_num=which(MegaData$INCLUDE==1)) %dopar% {
#for (stock_num in which(MegaData$INCLUDE==1)){
stock_subset_i<-which(Cleanmegacell[,stock_num] > 0) #that's K density map so the values are < 1
distance_mat_full_prop <- distance_mat_full %>% filter(pos1 %in% stock_subset_i, pos2 %in% stock_subset_i) %>% group_by(pos1) %>% mutate(biom_prop = exp(-( dist^2 / (2*(sigma^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-dist) %>% as.data.table()
#fts is the fastest in saving and loading files.
fst::write.fst(distance_mat_full_prop , here("data","connect_matrix",paste0(stock_num,"_connect.fst")))
}
doParallel::stopImplicitCluster()
}
test<-fst::read.fst(here("data","connect_matrix",paste0(1,"_connect.fst")))
head(test)
head(MegaData)
MegaData$bvk_fin<-bvk_calculated$bvk_calc
# #--test the code
# stock_num<-1
# bvk_equi <- func_evaluateMPA(stock_num, Cleanmegacell,biol_data,distance_mat_full,MegaData)
# head(bvk_equi)
# dim(bvk_equi)
# #--store the results and collate later
# collate_bvk_equi<-list()
# nstock<-2#dim(MegaData)[1]
# for (stock_num in 1:nstock){
#   collate_bvk_equi[[stock_num]] <- func_evaluateMPA(stock_num, Cleanmegacell,biol_data,distance_mat_full,MegaData)$bvk_equi
# }
# collate_bvk_equi_merged <- data.frame(do.call("cbind",collate_bvk_equi))
# colnames(collate_bvk_equi_merged)<-MegaData$stockid[1:nstock]
# head(collate_bvk_equi_merged)
# dim(collate_bvk_equi_merged)
# #ok, done testing. Now, do parallel compute
#--parallel compute
nstock<-dim(MegaData)[1]
ptm <- proc.time()
registerDoParallel(detectCores()/2)
stock_include<-which(MegaData$INCLUDE==1)[1:5]#c(1,3,5)#which(MegaData$INCLUDE==1)#c(1,3,5)#edit this. include only stocks for the analysis
#collate_bvk_equi_merged <- foreach(stock_num=stock_include[1:length(stock_include)], .combine='cbind') %dopar% {
collate_bvk_equi_merged <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA(stock_num, Cleanmegacell,biol_data,distance_mat_full,MegaData)$bvk_equi
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_bvk_equi_merged)<-MegaData$stockid[stock_include]
head(collate_bvk_equi_merged)
dim(collate_bvk_equi_merged)
#plot
#collate_bvk_equi_merged[is.na(collate_bvk_equi_merged)] <- 0 #never do this.
collate_bvk_equi_merged[collate_bvk_equi_merged>1]<-1 #cap to 1
plotme<-rowMeans(collate_bvk_equi_merged,na.rm = TRUE)
plot(plotme)
plot(plotme,BvKperCell)
CleanCoordmegacell_EEZ_wMPA %>% ggplot(aes(x=lon,y=lat,fill=plotme)) + scale_fill_viridis_c(limits = c(0, max(plotme))) + geom_raster() #ok, great
#--to do
#calculation of tourism values can be incorporated in the function
# biomass_withMPA <- foreach(i=1:2, .combine='rbind') %dopar% {
#   EvaluateMPA <- MPAcell #this is inside since we need to close each pixel and put it back
#   EvaluateMPA[nonMPAposition[i]]<-1
#
#   # for (t in 1:20){
#   #   biom_diff <- distance_mat_full_prK[biom_diff] %>% mutate(Bdist=B*biom_prop, Growth=biom_prop*r*B) %>% group_by(pos2) %>% dplyr::select(pos2,Bdist,Growth) %>% summarize(B_add=sum(Bdist),G_add=sum(Growth)) %>%
#   #     mutate(B=((1-(E*(1-EvaluateMPA)))*B_add)+pmax(G_add*(1-(biom_diff$B/KperCell)),0)) %>% dplyr::rename(pos1 = pos2) %>% dplyr::select(pos1,B) %>% as.data.table()
#   # }
#   sum(biom_diff$B)
# }
# doParallel::stopImplicitCluster()
# (proc.time() - ptm)/60 #check process time in minutes
#
# plot(biomass_withMPA) #ok, looks good
#--parallel compute
nstock<-dim(MegaData)[1]
ptm <- proc.time()
registerDoParallel(detectCores()/2)
stock_include<-which(MegaData$INCLUDE==1)#c(1,3,5)#which(MegaData$INCLUDE==1)#c(1,3,5)#edit this. include only stocks for the analysis
#collate_bvk_equi_merged <- foreach(stock_num=stock_include[1:length(stock_include)], .combine='cbind') %dopar% {
collate_bvk_equi_merged <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA(stock_num, Cleanmegacell,biol_data,distance_mat_full,MegaData)$bvk_equi
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_bvk_equi_merged)<-MegaData$stockid[stock_include]
head(collate_bvk_equi_merged)
dim(collate_bvk_equi_merged)
#plot
#collate_bvk_equi_merged[is.na(collate_bvk_equi_merged)] <- 0 #never do this.
collate_bvk_equi_merged[collate_bvk_equi_merged>1]<-1 #cap to 1
plotme<-rowMeans(collate_bvk_equi_merged,na.rm = TRUE)
plot(plotme)
plot(plotme,BvKperCell)
CleanCoordmegacell_EEZ_wMPA %>% ggplot(aes(x=lon,y=lat,fill=plotme)) + scale_fill_viridis_c(limits = c(0, max(plotme))) + geom_raster() #ok, great
#--to do
#calculation of tourism values can be incorporated in the function
# biomass_withMPA <- foreach(i=1:2, .combine='rbind') %dopar% {
#   EvaluateMPA <- MPAcell #this is inside since we need to close each pixel and put it back
#   EvaluateMPA[nonMPAposition[i]]<-1
#
#   # for (t in 1:20){
#   #   biom_diff <- distance_mat_full_prK[biom_diff] %>% mutate(Bdist=B*biom_prop, Growth=biom_prop*r*B) %>% group_by(pos2) %>% dplyr::select(pos2,Bdist,Growth) %>% summarize(B_add=sum(Bdist),G_add=sum(Growth)) %>%
#   #     mutate(B=((1-(E*(1-EvaluateMPA)))*B_add)+pmax(G_add*(1-(biom_diff$B/KperCell)),0)) %>% dplyr::rename(pos1 = pos2) %>% dplyr::select(pos1,B) %>% as.data.table()
#   # }
#   sum(biom_diff$B)
# }
# doParallel::stopImplicitCluster()
# (proc.time() - ptm)/60 #check process time in minutes
#
# plot(biomass_withMPA) #ok, looks good
library(raster)
library(sf)
library(tidyverse)
library(ggspatial)
install.packages("ggspatial")
gocp_project_dir <- "~/Volumes/GoogleDrive/Shared drives/emlab/projects/current-projects/ocean-conservation-priorities"
emlab_data_dir <- "~/Volumes/Google Drive/Shared drives/emlab/data"
this_project_dir <- "~/Volumes/Google Drive/Shared drives/emlab/projects/current-projects/ps-tourism"
ocean_low_res_moll <- raster::raster(file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif"))
gocp_project_dir <- "~/Volumes/GoogleDrive/Shared \drives/emlab/projects/current-projects/ocean-conservation-priorities"
gocp_project_dir <- "~/Volumes/GoogleDrive/Shared\ drives/emlab/projects/current-projects/ocean-conservation-priorities"
ocean_low_res_moll <- raster::raster(file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif"))
emlab_data_dir <- "~/Volumes/Google Drive/Shared\ drives/emlab/data"
ocean_low_res_moll <- raster::raster(file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif"))
file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif")
emlab_data_dir <- "/Volumes/Google Drive/Shared\ drives/emlab/data"
file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif")
file.exists("/Volumes/Google Drive/Shared drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif")
emlab_data_dir <- "/Volumes/Google Drive/Shared drives/emlab/data"
file.exists("/Volumes/Google Drive/Shared drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif")
file.exists("/Volumes/GoogleDrive/Shared\ drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif ")
file.exists("/Volumes/GoogleDrive/Shared drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif ")
file.exists("~/GoogleDrive/Shared drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif ")
dir.exists("/Volumes/GoogleDrive/Shared drives/emlab/data/ocean-conservation-priorities/inputs")
file.exists("/Volumes/GoogleDrive/Shared drives/emlab/data/ocean-conservation-priorities/inputs/ocean_low_res_moll.tif")
gocp_project_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/projects/current-projects/ocean-conservation-priorities"
# Path to the emLab data directory
emlab_data_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/data"
# Path to the Pristine Seas tourism directory on the emLab Google Drive
this_project_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/projects/current-projects/ps-tourism"
ocean_low_res_moll <- raster::raster(file.path(emlab_data_dir, "ocean-conservation-priorities", "inputs", "ocean_low_res_moll.tif"))
mpatlas <- sf::st_read(file.path(emlab_data_dir, "mpa-atlas", "MPAtlas_20201223_clean", "mpatlas_20201223_clean.shp"))
mpatlas_info <- mpatlas %>%
st_drop_geometry()
mpas_to_include <- c(15907, 14985, 14982, 12864, 9234, 737, 9051, 68813326,
68807894, 68819490, 15624, 68819076, 68818813, 68808197)
mpas_to_exclude <- c(68808626, 68808627)
highly_mpas <- mpatlas %>%
filter(is_mpa == 1,
status == "Designated",
implemente == 1) %>%
filter(!mpa_id %in% mpas_to_exclude) %>%
filter(no_take %in% c("All") | mpa_id %in% mpas_to_include | country == "GAB")
mpas_for_review <- mpatlas %>%
filter(is_mpa == 1,
status == "Designated",
implemente == 1) %>%
filter(!mpa_id %in% mpas_to_exclude) %>%
filter(no_take %in% c("All", "Part") | mpa_id %in% mpas_to_include) %>%
filter(!mpa_id %in% highly_mpas$mpa_id, iucn_categ %in% c("II", "Ia", "Ib")) %>%
arrange(desc(rep_m_area))
highly_mpas <- bind_rows(highly_mpas, mpas_for_review) %>%
st_set_crs(st_crs(mpatlas))
ocean_df <- stack(ocean_low_res_moll, highly_mpas_raster) %>%
raster::as.data.frame(xy = T) %>%
set_names(c("lon", "lat", "ocean", "f_highly_mpa")) %>%
filter(!is.na(ocean)) %>%
rowid_to_column(var = "cell_id") %>%
as_tibble()
highly_mpas_info <- highly_mpas %>% st_drop_geometry()
highly_mpas_raster <- highly_mpas %>%
st_transform(st_crs(ocean_low_res_moll)) %>%
rasterize(ocean_low_res_moll, getCover = T) %>%
mask(ocean_low_res_moll)
ocean_df <- stack(ocean_low_res_moll, highly_mpas_raster) %>%
raster::as.data.frame(xy = T) %>%
set_names(c("lon", "lat", "ocean", "f_highly_mpa")) %>%
filter(!is.na(ocean)) %>%
rowid_to_column(var = "cell_id") %>%
as_tibble()
spp_files <- tibble(filepath = list.files(c(file.path(gocp_project_dir, "data", "02_processed", "species_distributions", "birdlife"),
file.path(gocp_project_dir, "data", "02_processed", "species_distributions", "aquamaps")),
full.names = T),
valid_sci_name = str_replace_all(str_remove(basename(filepath), "\\.tif"), "_", " ")) %>%
arrange(valid_sci_name)
smts_info <- tibble(filepath = list.files(file.path(gocp_project_dir, "data", "02_processed","seamounts"), full.names = T))
provs_info <- tibble(filepath = list.files(file.path(gocp_project_dir, "data", "02_processed", "biogeography"), full.names = T, pattern = "\\.tif"))
biodiversity_df <- stack(c(spp_files$filepath, smts_info$filepath, provs_info$filepath))
biodiversity_df <- biodiversity_df %>%
raster::as.data.frame(xy = T)
biodiversity_df <- biodiversity_df %>%
rename("lon" = "x", "lat" = "y") %>%
inner_join(ocean_df %>%
select(lon, lat, cell_id)) %>%
select(lon, lat, cell_id, everything()) %>%
as_tibble()
bio_feature_names <- colnames(biodiversity_df)[-c(1:3)]
spp_wts <- data.table::fread(file.path(gocp_project_dir, "data", "02_processed", "species_list", "spp_weights.csv")) %>%
as_tibble() %>%
rename(w = spp_weight)
smts_wts <- tibble(filepath = list.files(file.path(gocp_project_dir, "data", "02_processed","seamounts"), full.names = T)) %>%
mutate(w = sum(spp_wts$w)/n())
provs_wts <- tibble(filepath = list.files(file.path(gocp_project_dir, "data", "02_processed", "biogeography"), full.names = T, pattern = "\\.tif")) %>%
mutate(w = sum(spp_wts$w)/n())
bio_features_info <- bind_rows(spp_wts %>%
mutate(sub_goal = "species"),
smts_wts %>%
mutate(sub_goal = "seamounts"),
provs_wts %>%
mutate(sub_goal = "provinces"))
n_bio_features <- nrow(bio_features_info)
features_matrix <- biodiversity_df %>%
select(-lon,-lat,-cell_id) %>%
as.matrix()
rownames(features_matrix) <- biodiversity_df$cell_id
stopifnot(
sum(map_lgl(biodiversity_df %>%
select(-lon,-lat,-cell_id), is.numeric)) == ncol(features_matrix)
)
norm_features_matrix <- sweep(features_matrix, 2, colSums(features_matrix, na.rm = T), FUN = "/")
stopifnot(
sum(colSums(norm_features_matrix, na.rm = T)) == ncol(features_matrix)
)
norm_features_matrix <- norm_features_matrix[rowSums(is.na(norm_features_matrix)) != ncol(norm_features_matrix), ]
stopifnot(
identical(colnames(norm_features_matrix),
biodiversity_df %>%
select(-lon,-lat,-cell_id) %>%
colnames())
)  # Is the order of the features mantained?
norm_features_matrix[is.na(norm_features_matrix)] <- 0
z_bio <- 0.25
bio_weights <- bio_features_info$w
bio_abatable_impacts_df <- raster(file.path(gocp_project_dir,
"data", "02_processed", "impacts", "chi", "abatable_impacts_5_yr_avg_log.tif")) %>%
raster::as.data.frame(xy = T) %>%
set_names(c("lon", "lat", "Ia")) %>%
inner_join(ocean_df) %>%
as_tibble() %>%
replace_na(list(Ia = 0))
bio_unabatable_impacts_df <- raster(file.path(gocp_project_dir,
"data", "02_processed", "impacts", "chi", "unabatable_impacts_5_yr_avg_log.tif")) %>%
raster::as.data.frame(xy = T) %>%
set_names(c("lon", "lat", "Iu")) %>%
inner_join(ocean_df) %>%
as_tibble()%>%
replace_na(list(Iu = 0))
v_out_matrix <- norm_features_matrix %>%
sweep(1, (1 - bio_abatable_impacts_df$Ia), FUN = "*") %>%
sweep(1, (1 - bio_unabatable_impacts_df$Iu), FUN = "*")
v_in_matrix <- norm_features_matrix %>%
sweep(1, (1 - bio_unabatable_impacts_df$Iu), FUN = "*")
v_diff_matrix <- norm_features_matrix %>%
sweep(1, (bio_abatable_impacts_df$Ia - bio_abatable_impacts_df$Ia*bio_unabatable_impacts_df$Iu), FUN = "*")
v_bau_per_species <- v_out_matrix %>%
colSums(na.rm = T)
mean(v_bau_per_species)
mean(v_bau_per_species^z_bio)
bau_benefit <- sum(bio_weights*v_bau_per_species^z_bio)
bau_benefit/sum(bio_weights*1^z_bio)
v_full_mpa_per_species <- v_in_matrix %>%
colSums(na.rm = T)
mean(v_full_mpa_per_species)
mean(v_full_mpa_per_species^z_bio)
max_benefit <- sum(bio_weights*v_full_mpa_per_species^z_bio)
max_benefit/sum(bio_weights*1^z_bio)
v_diff_per_species <- v_diff_matrix %>%
colSums(na.rm = T)
all.equal(v_full_mpa_per_species - v_diff_per_species, v_bau_per_species)
mean(v_diff_per_species) #  26% increase in suitable habitat remaining
total_benefit_diff <- sum(bio_weights*v_full_mpa_per_species^z_bio) - sum(bio_weights*v_bau_per_species^z_bio)
total_benefit_diff/sum(bio_weights*v_bau_per_species^z_bio) # a max of 41% increase in spp permanence
save(ocean_df, highly_mpas, highly_mpas_raster,
biodiversity_df, bio_features_info, n_bio_features, bio_feature_names, norm_features_matrix, bio_weights,
v_in_matrix, v_out_matrix, v_diff_matrix, v_bau_per_species, v_full_mpa_per_species,
bau_benefit, max_benefit,total_benefit_diff,
file = file.path(this_project_dir,  "data", "02_processed_data", "bio_model_input.RData"))
save(ocean_df, highly_mpas, highly_mpas_raster,
biodiversity_df, bio_features_info, n_bio_features, bio_feature_names, norm_features_matrix, bio_weights,
v_in_matrix, v_out_matrix, v_diff_matrix, v_bau_per_species, v_full_mpa_per_species,
bau_benefit, max_benefit,total_benefit_diff,
file = file.path(this_project_dir,  "data", "02-processed-data", "bio_model_input.RData"))
this_project_dir
save(ocean_df, highly_mpas, highly_mpas_raster,
biodiversity_df, bio_features_info, n_bio_features, bio_feature_names, norm_features_matrix, bio_weights,
v_in_matrix, v_out_matrix, v_diff_matrix, v_bau_per_species, v_full_mpa_per_species,
bau_benefit, max_benefit,total_benefit_diff,
file = file.path(this_project_dir,  "data", "02-processed-data", "bio_model_input.RData"))
save(v_out_matrix, v_in_matrix, bio_weights, bau_benefit, total_benefit_diff,
file =  file.path(this_project_dir,  "data", "02_processed_data", "minimal_bio_model_input.RData"))
save(v_out_matrix, v_in_matrix, bio_weights, bau_benefit, total_benefit_diff,
file =  file.path(this_project_dir,  "data", "02-processed-data", "minimal_bio_model_input.RData"))
here::here()
here::here("scripts", "functions")
z_bio <- 0.25
library(raster)
library(sf)
library(tidyverse)
library(ggspatial)
emlab_data_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/data"
# Path to the Pristine Seas tourism directory on the emLab Google Drive
this_project_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/projects/current-projects/ps-tourism"
sapply(list.files(
pattern = "[.]R$",
path = here::here("scripts", "functions"),
full.names = TRUE
),
source)
load(file = file.path(this_project_dir,  "data", "02_processed_data", "minimal_bio_model_input.RData"))
load(file = file.path(this_project_dir,  "data", "02-processed-data", "minimal_bio_model_input.RData"))
is_mpa_vect <- ocean_df$f_highly_mpa > 0.5 # select pixels that are at least 50% highly protected
protected_cell_ids <- ocean_df$cell_id[is_mpa_vect]
protected_cells <- matrix(is_mpa_vect,
nrow = 1,
ncol = length(is_mpa_vect))
library(raster)
library(sf)
library(tidyverse)
library(ggspatial)
### NOTE - you may have to adjust these paths depending on where your computer has mounted the Google Drive files
# Path to the emLab data directory
emlab_data_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/data"
# Path to the Pristine Seas tourism directory on the emLab Google Drive
this_project_dir <- "/Volumes/GoogleDrive/Shared drives/emlab/projects/current-projects/ps-tourism"
### -----------------------------------------------------------
### Section 2 - Source functions and load input data ----------
### -----------------------------------------------------------
# Source functions
sapply(list.files(
pattern = "[.]R$",
path = here::here("scripts", "functions"),
full.names = TRUE
),
source)
# Load data files necessary for biodiversity model
load(file = file.path(this_project_dir,  "data", "02-processed-data", "bio_model_input.RData"))
z_bio <- 0.25
sum_v_outs <- v_out_matrix[!protected_cells, ] %>%
colSums(na.rm = T)
sum_v_in <- v_in_matrix[protected_cells, ]%>%
colSums(na.rm = T)
b_benefit <- sum(bio_weights*(sum_v_in + sum_v_outs)^z_bio)
(b_benefit - bau_benefit)/total_benefit_diff # Can be interpreted as a conservative measure of the benefit of today's MPAs
z_bio <- 0.25
is_mpa_vect <- ocean_df$f_highly_mpa > 0.5 # select pixels that are at least 50% highly protected
protected_cell_ids <- ocean_df$cell_id[is_mpa_vect]
protected_cells <- matrix(is_mpa_vect,
nrow = 1,
ncol = length(is_mpa_vect))
sum_v_outs <- v_out_matrix[!protected_cells, ] %>%
colSums(na.rm = T)
sum_v_in <- v_in_matrix[protected_cells, ]%>%
colSums(na.rm = T)
b_benefit <- sum(bio_weights*(sum_v_in + sum_v_outs)^z_bio)
(b_benefit - bau_benefit)/total_benefit_diff #Can be interpreted as a conservative measure of the benefit of today's MPA
calculate_relative_bio_benefit(is_mpa_vect = is_mpa_vect,
v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix,
weights  = bio_weights,
z_bio = z_bio,
bau_benefit = bau_benefit,
total_benefit_diff = total_benefit_diff)
is_mpa_vect_all <- is_mpa_vect[is_mpa_vect==F] = T
is_mpa_vect_all <- is_mpa_vect
is_mpa_vect_all[is_mpa_vect_all==F] = T
calculate_relative_bio_benefit(is_mpa_vect = is_mpa_vect_all,
v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix,
weights  = bio_weights,
z_bio = z_bio,
bau_benefit = bau_benefit,
total_benefit_diff = total_benefit_diff)
=======
foreach(stock_num=stocklist) %dopar% {
stock_subset_i <- which(transformed_stockdistrib[,stock_num+5] > 0)
#included here: filter distance
distance_mat_full_prop_adult <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$homerange_radius[stock_num]) %>% group_by(source) %>% mutate(biom_prop = 1/n()) %>% dplyr::select(-distance) %>% as.data.table()
# distance_mat_full_prop <- distance_mat_full %>% filter(pos1 %in% stock_subset_i, pos2 %in% stock_subset_i) %>% group_by(pos1) %>% mutate(biom_prop = exp(-( dist^2 / (2*(sigma^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-dist) %>% as.data.table()
#fts is the fastest in saving and loading files.
fst::write.fst(distance_mat_full_prop_adult , paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix_adult/",stock_num,"_connect_adult.fst"))
}
doParallel::stopImplicitCluster()
}
##--for checking the code
#stock_subset_i <- which(transformed_stockdistrib[,255+5] > 0)
#distance_mat_full_prop_adult <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$homerange_radius[stock_num]) %>% group_by(source) %>% mutate(biom_prop = 1/n()) %>% dplyr::select(-distance) %>% as.data.table()
#distance_mat_full_prop_adult %>% group_by(source) %>% summarize(sum(biom_prop))
#distance_mat_full_prop_adult %>% group_by(sink) %>% summarize(sum(biom_prop))
#test<-fst::read.fst(paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/1_connect_larvae.fst"))
#head(test)
##-- Main code that evaluates biomass change for each stock and biodiversity score change
#-- visualize number of dives distribution using histogram with logarithmic scale
ggplot(data.frame(log(dives_input$n_dives_extrap)), aes(log(dives_input$n_dives_extrap))) + geom_histogram(bins=20)
dive_per_country <- left_join(dives_input,cell_id_with_country_kat_withregion,by="cell_id")
iso_library <- dive_per_country %>% select(sovereign1,territory1,iso_sov1,iso_ter1) %>% unique() %>% arrange(sovereign1) %>% filter(!is.na(sovereign1))
#filter CountryCode==NA and try to fill out details
no_info_pixels <- dive_per_country %>% filter(is.na(CountryCode))
no_info_pixels$cell_id #ok, "numeric(0)" means that all pixels have info now (we filled out the 5 pixels with no country info, i.e., New Zealand).
#-- Data Check: check nearest distance to fill out missing pixel info
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[1]-lon)+abs(no_info_pixels$lat[1]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 1 is New Zealand
# #New Zealand Country code is 95
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[2]-lon)+abs(no_info_pixels$lat[2]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 2 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[3]-lon)+abs(no_info_pixels$lat[3]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 3 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[4]-lon)+abs(no_info_pixels$lat[4]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 4 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[5]-lon)+abs(no_info_pixels$lat[5]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 5 is New Zealand
# --This code is just for verifying that indeed the 5 points are all in New Zealand
# land_shp_moll<-readRDS(file = "/Users/ren/Documents/CODES/FoodProvision/land_shp_moll.rds")
# no_info_pixels %>% ggplot(aes(x=lon,y=lat)) + geom_point(color="red") + #scale_fill_viridis()+#option="plasma")+#scale_fill_gradient(color=viridis)+#scale_fill_gradient(low="white", high="#00539CFF")+#guides(fill=guide_legend())+
#   theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank())+
#   geom_raster()+
#   geom_sf(data = land_shp_moll,fill="darkgray", lwd = 0.1,  inherit.aes = F)
#-- load country classification (SIDS, developing, etc.)
country_classification <- read.csv(here("data","UN_territory_sovereign_classification.csv"))
#country_classification$SIDS <-as.factor(country_classification$Classification)
country_classification_with_iso <- left_join(country_classification,iso_library,by=c("sovereign1","territory1"))
country_classification_kat <- read.csv(here("data","country_status_lookup_manual_category.csv")) %>% mutate(Classification_kat = ifelse(manual_development_status=="Developed", "Developed", "Developing")) %>%
select(iso3,Classification_kat) %>% dplyr::rename(iso_ter1 = iso3)
#-- note from Kat: use "development_status" -- developed and others.
country_classification_with_iso_and_class <- left_join(country_classification_with_iso,country_classification_kat,by="iso_ter1") %>% mutate(match = (Classification==Classification_kat))
#-- plot number of dives per country
head(dive_per_country)
plot_number_dives <- dive_per_country %>% group_by(territory1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap)) %>% left_join(country_classification,by="territory1") %>%
arrange(-n_dive) %>% slice(1:50) %>% ggplot(aes(x = reorder(as.factor(territory1), n_dive/1000000), y = n_dive/1000000, fill=Classification))+
geom_bar(stat = "identity")+ theme_classic()+ coord_flip()+ labs(y = "Dive per year, million")+theme(axis.title.y = element_blank())
plot_number_dives
#-- plot number of dive pixels per country
plot_number_divepexels_country <- dive_per_country %>% group_by(territory1) %>% dplyr::summarize(n_divesites=n()) %>% filter(territory1!="NA") %>% left_join(country_classification,by="territory1") %>%
arrange(-n_divesites) %>% slice(1:50) %>% ggplot(aes(x = reorder(as.factor(territory1), n_divesites), y = n_divesites, fill=Classification))+
geom_bar(stat = "identity")+ theme_classic()+ coord_flip()+ labs(y = "Number of dive site pixel")+theme(axis.title.y = element_blank())
plot_number_divepexels_country
##-- correlate # of dives with on-reef values
ndive_per_sovereign <- dive_per_country %>% group_by(sovereign1,iso_sov1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap))
head(ndive_per_sovereign)
onreef_values <- read.csv(here("data","tourism_reef_values","Tourvalues_Spalding.csv")) %>% group_by(iso_sov1) %>% summarise(onreef_value=sum(OnReef))
head(onreef_values)
correlate_dive_and_value <- merge(x=ndive_per_sovereign,y=onreef_values,by="iso_sov1")
head(correlate_dive_and_value)
plot_correlate_dive_and_value<- ggplot(correlate_dive_and_value, aes(x=onreef_value/1000000,y=n_dive/1000000))+geom_point()+geom_smooth(method = lm,colour="gray")+
geom_text_repel(aes(onreef_value/1000000, n_dive/1000000, label = sovereign1), size = 3)+
labs(x="On-reef tourism value, billion US$", y = "Dive per year, million")+theme_classic()
plot_correlate_dive_and_value
##--correlate # of dives with flikr data
ndive_per_sovereign <- dive_per_country %>% group_by(sovereign1,iso_sov1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap))
head(ndive_per_sovereign)
flickr_data <- read.csv(here("data","flickr","flickr_webscraped_data_raw_v11.csv"))
flickr_data_sum <- flickr_data %>% group_by(iso_code) %>% dplyr::summarize(count=n()) %>% dplyr::rename(iso_sov1=iso_code)
head(flickr_data_sum)
correlate_dive_and_flickr <- merge(x=ndive_per_sovereign,y=flickr_data_sum,by="iso_sov1") %>% filter(is.na(iso_sov1)==F)
head(correlate_dive_and_flickr)
plot_correlate_dive_and_flickr <- ggplot(correlate_dive_and_flickr, aes(x=count,y=n_dive/1000000))+geom_point()+geom_smooth(method = lm,colour="gray")+
geom_text_repel(aes(count, n_dive/1000000, label = sovereign1), size = 3)+
labs(x="Number of flickr photos", y = "Dive per year, million")+theme_classic()
#figure 1 main
figure1<-cowplot::plot_grid(plot_number_divepexels_country, plot_number_dives,plot_correlate_dive_and_value,plot_correlate_dive_and_flickr, ncol = 2, labels = "AUTO",rel_heights=c(1,0.5))
figure1
ggsave(here("figures","main","plot_number_dives.jpg"),figure1, width = 20, height = 20, units = "cm")
#saving a country file for me to assign country development categorization
##---[no need to run] head(dive_per_country)
##---[no need to run] dive_per_country %>% select(sovereign1) %>% unique() %>% write.csv(.,file = here("data","country_classification.csv"))
##---[no need to run] dive_per_country %>% select(territory1) %>% unique() %>% write.csv(.,file = here("data","territory_classification.csv"))
##---[no need to run] dive_per_country %>% select(sovereign1,territory1) %>% unique() %>% arrange(sovereign1) %>% filter(!is.na(sovereign1)) %>% write.csv(.,file = here("data","territory_sovereign_classification.csv"))
##---[no need to run] checkme <- read.csv(here("data","UN_territory_sovereign_classification.csv"))
#prep data to plot the world's dive sites
ocean_coordinates_dive_suitable <- left_join(ocean_coordinates,suitability_input,by="cell_id")
ocean_coordinates_dive_suitable_v2 <- left_join(ocean_coordinates_dive_suitable,dives_input,by="cell_id")
#plot suitability later or current locations of dive sites
world_dive_sites <- ocean_coordinates_dive_suitable_v2 %>% mutate(suitable = replace_na(suitable,0)) %>% ggplot() + geom_raster(aes(x=lon,y=lat,fill=suitable)) + scale_fill_gradientn(colours=c("black","orange")) #ok, great
world_dive_sites
ggsave(here("figures","supplementary","world_dive_sites.jpg"),world_dive_sites, width = 20, height = 12, units = "cm")
#-- MPA location. Assume that a pixel is an MPA is f_highly_mpa>=0.5.
MPA_vec <- transformed_stockdistrib %>% dplyr::select(cell_id,f_highly_mpa) %>% mutate(f_highly_mpa = (f_highly_mpa>=0.5))
MPA_loc <- MPA_vec %>% filter(f_highly_mpa=="TRUE") %>% select(cell_id)
#-- Question: How many of the suitable dive sites are already in MPAs?
divesite_in_MPA <- suitability_input %>% filter(cell_id %in% MPA_loc$cell_id) %>% dim()
dive_cell_id_MPA <- suitability_input %>% filter(cell_id %in% MPA_loc$cell_id) %>% select(cell_id)
divesite_in_MPA#22 pixels out of 1814
divesite_in_MPA[1]*100/dim(dives_input)[1] #1.21% of the dive sites are inside MPA (using 50 x 50km resolution).
##--biodiversity prep
#-- load the functions
# sapply(list.files(pattern = "[.]R$", path = here::here("scripts", "functions"), full.names = TRUE),source)
source(here("scripts", "functions","calculate_relative_bio_benefit.R"))
source(here("scripts", "functions","func_evaluateMPA_explicit.R"))
#-- load data files necessary for biodiversity model
load(file = file.path(this_project_dir,  "data", "02-processed", "model-inputs", "bio_model_input.RData"))
# set Z for biodiversity
z_bio <- 0.25
##---BIODIVERSITY CODE
# Calculate biodiversity benefit from today's protected cells
bio_benefit_current<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_highly_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#Biodiv benefits of zero MPA
MPA_vec$f_zero_mpa<-FALSE
bio_benefit_zero<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_zero_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#Biodiv benefits of 100% ocean in MPA
MPA_vec$f_all_mpa<-TRUE
bio_benefit_all<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_all_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#% increase from zero MPA to current MPA
(bio_benefit_current-bio_benefit_zero)*100/bio_benefit_zero
#% increase from current MPA to all MPA
(bio_benefit_all-bio_benefit_current)*100/bio_benefit_current
#biodiversity score, no MPA
bio_benefit_zero/max_benefit_allthreats #0.5326662
#biodiversity score, current MPA
bio_benefit_current/max_benefit_allthreats #0.5445721
#biodiversity score, all MPA
bio_benefit_all/max_benefit_allthreats #0.7563106
#% increase from current MPA to all MPA
(bio_benefit_all-bio_benefit_current)*100/bio_benefit_current
#% increase from current MPA to all threats solved (not needed)
(max_benefit_allthreats-bio_benefit_current)*100/bio_benefit_current
##----- BIOMASS CODE
#--test:
#func_evaluateMPA_explicit(stock_num=1, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc)$biomass
rerun_biomass_code <- 0 #1 for on, 0 to switch this off
if(rerun_biomass_code == 1){
stock_include <- stocklist#c(1,2,4,5,6)#stocklist[8] #c(1,2,4,5,6) #comment this. this is just a placeholder for building our code
ptm <- proc.time()
registerDoParallel(detectCores()/2)
collate_biomass_equi_merged <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA_explicit(stock_num, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc)$biomass
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_biomass_equi_merged)<-MegaData_filtered_step_fin$stockid[stock_include]
dim(collate_biomass_equi_merged)
saveRDS(collate_biomass_equi_merged, file = here("data","collate_biomass_equi_merged.rds"))
}
collate_biomass_equi_merged<-readRDS(file = here("data","collate_biomass_equi_merged.rds"))
##--Calculate B/K per pixel
#compute K per pixel of our stock list
max(transformed_stockdistrib[6:1155],na.rm=T)
min(transformed_stockdistrib[6:1155],na.rm=T)
full_stock_distrib <- transformed_stockdistrib[6:1155]
filtered_stock_distrib <- full_stock_distrib %>% select(c(stocklist))#full_stock_distrib[,stocklist_index] #this is the stock distrib of our filtered stock. Max value is 1 and with NAs
dim(filtered_stock_distrib) #149547 x 813
#K/geogrange
Kmultiplyer <- MegaData_filtered_step_fin %>% select(Kperpixel) %>% slice(stocklist_index) %>% data.frame()
head(Kmultiplyer)
dim(Kmultiplyer)
min(Kmultiplyer)
df_Kmultiplyer <- t(data.frame(rep(Kmultiplyer,each=149547)))
<<<<<<< HEAD
dim(df_Kmultiplyer)
min(df_Kmultiplyer)
#filtered_stock_distrib[is.na(filtered_stock_distrib)] <- 0 #Replace NAs to 0
dim(filtered_stock_distrib) #stock distribution we considered in our model
dim(df_Kmultiplyer)
#check number of pixels per stock
#---rencheck
npixel_per_stock <- colSums(filtered_stock_distrib,na.rm=T)
length(npixel_per_stock)
plot(npixel_per_stock)
min(npixel_per_stock)
#---
#check number of stocks per pixel
#---rencheck
nstock_per_pixel <- rowSums(filtered_stock_distrib,na.rm=T)
length(nstock_per_pixel)
min(nstock_per_pixel)
rencheck <- ocean_coordinates
rencheck$nstock_per_pixel <- nstock_per_pixel
dim(rencheck)
head(rencheck)
rencheck2 <- rencheck %>% filter(cell_id %in% suitability_input$cell_id)
dim(rencheck2)
rencheck2 %>% filter(nstock_per_pixel==0) #oh knows! T15 stocks?
#check other way
dim(full_stock_distrib)
head(full_stock_distrib)
filt <- full_stock_distrib %>% select(c(stocklist))
oi <- rowSums(filt,na.rm=T) #149547
min(oi[suitability_input$cell_id]) #so there are pixels with no biomass because some stocks were removed.
#---
Kdistrib <- filtered_stock_distrib * df_Kmultiplyer#multiply with Kmultiplyer
dim(Kdistrib)
plot(Kdistrib[,1])
#check if the above is correct
filtered_stock_distrib %>% select(`Fis-29732`) %>% filter(!is.na(`Fis-29732`))
Kdistrib %>% select(`Fis-29732`) %>% filter(!is.na(`Fis-29732`)) #ok
TotalKperPixel <- rowSums(Kdistrib,na.rm=T) #colSums to get the K per pixel
#---rencheck
rencheck <- ocean_coordinates
rencheck$TotalKperPixel <- TotalKperPixel
dim(rencheck)
head(rencheck)
rencheck <- rencheck %>% filter(cell_id %in% suitability_input$cell_id)
dim(rencheck)
#---rencheck <- rencheck %>% filter(cell_id %in% dive_cell_id_unprotected)
suitability_input$cell_id
#k per pixel.
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=TotalKperPixel)) + scale_fill_viridis_c() + geom_raster()
#calculate B/K per pixel
BvK <- rowSums(collate_biomass_equi_merged,na.rm = TRUE)/TotalKperPixel
length(BvK)
max(BvK,na.rm=T)
BvK[order(-BvK)]
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK)) + scale_fill_viridis_c(limits = c(0, 1)) + geom_raster() #ok, great
##-----NOW, close all dive pixels and calculate BvK
head(suitability_input)
#change dive sites into MPAs
MPA_vec_dive <- transformed_stockdistrib %>% dplyr::select(cell_id,f_highly_mpa) %>% mutate(f_highly_mpa = (f_highly_mpa>=0.5)) %>% mutate(f_highly_mpa = replace(f_highly_mpa,cell_id %in% suitability_input$cell_id, TRUE))
#this is current MPA + converting all dive sites into MPA.
MPA_loc_dive <- MPA_vec_dive %>% filter(f_highly_mpa=="TRUE") %>% select(cell_id)
rerun_biomass_wMPAdive_code <- 0 #1 for on, 0 to switch this off
if(rerun_biomass_wMPAdive_code == 1){
ptm <- proc.time()
registerDoParallel(detectCores()/2)
collate_biomass_equi_merged_dive <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA_explicit(stock_num, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc_dive)$biomass
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_biomass_equi_merged_dive) <- MegaData_filtered_step_fin$stockid[stock_include]
saveRDS(collate_biomass_equi_merged_dive, file = here("data","collate_biomass_equi_merged_dive.rds"))
}
collate_biomass_equi_merged_dive <- readRDS(file = here("data","collate_biomass_equi_merged_dive.rds"))
#compute B/K per pixel
BvK_dive <- rowSums(collate_biomass_equi_merged_dive,na.rm = TRUE)/TotalKperPixel
#transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK_dive)) + scale_fill_viridis_c(limits = c(0, 1)) + geom_raster()
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK_dive)) + scale_fill_viridis_c() + geom_raster()
=======
>>>>>>> 276b6a98f17342aa5307967b1121c88b774461ab
>>>>>>> b5b4b1848f57c83f4edb119f0fc99ce7c8a91efb
