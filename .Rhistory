#-- load homerange and pld data predictions, then process
pld_data <- read.csv(here("data","homerange_pld_predictions","pld_rf_predictions_final.csv")) %>% dplyr::select(species,observed_PLD,predicted_PLD) %>% dplyr::rename(SciName = species)
#-- summarize in case of duplicates
pld_data_mean <- pld_data %>% group_by(SciName) %>% summarise(mean_observed_PLD = mean(observed_PLD), sd_observed_PLD = sd(observed_PLD), mean_predicted_PLD = mean(predicted_PLD))
head(pld_data_mean)
dim(pld_data_mean)
homerange_data <- read.csv(here("data","homerange_pld_predictions","homerange_rf_predictions_10112022.csv")) %>% dplyr::select(species,observed_homerange,predicted_homerange) %>% dplyr::rename(SciName = species)
homerange_data_mean <- homerange_data %>% group_by(SciName) %>% summarise(mean_observed_homerange = mean(observed_homerange), sd_observed_homerange = sd(observed_homerange), mean_predicted_homerange = mean(predicted_homerange))
head(homerange_data_mean)
species_list <- MegaData_filtered %>% dplyr::select(SciName) %>% unique()
dim(species_list)#811 species
db_with_pld <- left_join(species_list,pld_data_mean,by="SciName")
db_with_pld_hrange <- left_join(db_with_pld,homerange_data_mean)
head(db_with_pld_hrange)
dim(db_with_pld_hrange)
db_with_pld_hrange_filtered <- db_with_pld_hrange %>% mutate(PLD = ifelse(!is.na(mean_observed_PLD),mean_observed_PLD,mean_predicted_PLD), homerange = ifelse(!is.na(mean_observed_homerange),mean_observed_homerange,mean_predicted_homerange),
complete = ifelse((PLD>0 & homerange>0),1,0))
sum(db_with_pld_hrange_filtered$complete,na.rm=T) #610 species out of 811. Check what proportion of K this is
#-- merge with the full data list
MegaData_PLD_hrange <- left_join(MegaData_filtered,db_with_pld_hrange_filtered,by="SciName")
#-- max dispersal distance limit (3 sigma larvae)
3*1.33*(max(MegaData_PLD_hrange$PLD,na.rm=T)^1.3)*sqrt(pi/2) #18K
#-- add dispersal distance limit to the megadata file
MegaData_filtered_step2 <- MegaData_PLD_hrange %>% mutate(sigma_larvae = 1.33*(PLD^1.3)*sqrt(pi/2), dispersal_distance_limit = 3*sigma_larvae, homerange_radius = sqrt(homerange/pi))
head(MegaData_filtered_step2)
#-- add the geographic range of the stock
full_stock_distrib <- transformed_stockdistrib[6:1155]
geog_range_perstock<- colSums(full_stock_distrib,na.rm=T) %>% as.data.frame()
colnames(geog_range_perstock) <- c('geog_range')
geog_range_perstock$stockid <- row.names(geog_range_perstock)
head(geog_range_perstock)
MegaData_filtered_step3 <- left_join(MegaData_filtered_step2,geog_range_perstock,by="stockid")
MegaData_filtered_step_fin <- MegaData_filtered_step3 %>% mutate(Kperpixel = Kfin/geog_range)
head(MegaData_filtered_step_fin)
sum(MegaData_filtered_step_fin$complete, na.rm = T) #898
min(MegaData_filtered_step_fin$dispersal_distance_limit,na.rm=T)
#-- Remove stocks with no intersection with existing diving as their biomass will be unaffected by placing MPAs in existing dive sites
#-- load .rdata for input files [from Kat]
load(here("data","dive","tourism_model_input.RData")) %>% head()
## Input files content:"ocean_df_with_eezs" "dives_input" "suitability_input" "suitability_input" "price_country_region_input" "price_interpolated_input"
# #!!!!!!!!!
# #remove dive sites with no biomass information
# #-- stocks with no intersection with diving can be removed as they will be unaffected by MPAs in dive areas
# filter1 <- transformed_stockdistrib %>% filter(cell_id %in% suitability_input$cell_id)
# filter2 <- filter1 %>% select(-c(cell_id,lon,lat,ocean,f_highly_mpa))
# #check if all dive sites intersect with the stocks
# dive_with_biom <- rowSums(filter2,na.rm=T)
# suitability_input$with_stock <- (dive_with_biom>0)*1
# dive_with_no_biom <- suitability_input %>% filter(with_stock==0)
# dive_with_no_biom #ok, there are 7 dive sites that have no biomass information!!! so we should remove them.
#
# #revised Kat's file
# dives_input <- dives_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# dim(dives_input)
# head(dives_input)
# suitability_input <- suitability_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# price_country_region_input <- price_country_region_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
# price_interpolated_input <- price_interpolated_input %>% filter(! cell_id %in% dive_with_no_biom$cell_id)
#-- identify the stock that intersects with diving, and use only those stocks in the analysis
#-- stocks with no intersection with diving can be removed as they will be unaffected by MPAs in dive areas
dim(transformed_stockdistrib)
head(transformed_stockdistrib)
filter1 <- transformed_stockdistrib %>% filter(cell_id %in% suitability_input$cell_id)
dim(filter1)#there are 1807 dive sites x 1155
filter2 <- filter1 %>% select(-c(cell_id,lon,lat,ocean,f_highly_mpa))
dim(filter2) #1807 dive sites, 1150 stocks
rowSums(filter2,na.rm=T) %>% min() #all 1807 dive pixels have at least 1 dive site
# #check if all dive sites intersect with the stocks
# dive_with_biom <- rowSums(filter2,na.rm=T) %>% as.data.frame()
# dim(dive_with_biom)
# suitability_input$with_stock<- (dive_with_biom>0)*1
# dive_with_no_biom <- suitability_input %>% filter(with_stock==0)
# dive_with_no_biom #ok, there are 7 dive sites that have no biomass information!!! so we should remove them.
#Check if stocks intersect with a dive site
mysum <-colSums(filter2,na.rm=T) %>% as.data.frame()
head(mysum)
dim(mysum)
names(mysum)[1] <- "n_pixel_intersect"
sp_intersect_dive <- cbind(stockname = rownames(mysum), mysum)
dim(sp_intersect_dive)
head(sp_intersect_dive)
sp_intersect_dive %>% filter(n_pixel_intersect==0) %>% dim() ##remove 103 stocks with no intersection with diving!
stocklist_with_diving <- sp_intersect_dive %>% filter(n_pixel_intersect>0) %>% select(stockname)#which(mysum!=0)
dim(stocklist_with_diving)#1047 stocks that intersects with dive sites
head(stocklist_with_diving)
#-- now, how about stock list with complete parameters?
stocklist_complete_params <- MegaData_filtered_step_fin %>% filter(complete==1) #which(MegaData_filtered_step_fin$complete==1)
dim(stocklist_complete_params)#898 stocks with complete params
head(stocklist_complete_params)
#-- our final stocklist will be the intersection of the two
#stocklist <- stocklist_complete_params %>% filter(stockid %in% stocklist_with_diving$stockname) %>% select(stockid) #stocklist_complete_params[stocklist_complete_params %in% stocklist_with_diving]
#stocklist <- stocklist$stockid
stocklist <- stocklist_with_diving %>% filter(stockname %in% stocklist_complete_params$stockid)
stocklist <- stocklist$stockname
length(stocklist)#813 stocks with complete information
#stocklist in numeric, since it is easy to work with numbers
head(MegaData_filtered)
stocklist_index <- MegaData_filtered %>% filter(stockid %in% stocklist) %>% select(ID)
stocklist_index <- stocklist_index$ID
#--repeat because we removed stocks, so there will be pixels with no stocks
#-- check if all dive sites have country names
dive_with_eez_details <- left_join(dives_input,ocean_df_with_eezs,by="cell_id")
head(dive_with_eez_details) #we need to fill out the eez names of some countries
##-- load EEZ file, and use this to fill out missing details from the above EEZ file
eez_mollweide <- readRDS(file = here("data","eez_mollweide.rds"))
head(eez_mollweide)
dim(eez_mollweide)
#-- There are 5 pixels with diving but with no EEZ info. This creates country details for 5 pixels with no EEZ info, all New Zealand pixels
head(ocean_coordinates)
new_zealand_add_v2 <- ocean_coordinates %>% filter(cell_id %in% c(113701, 114285, 114866, 114868, 120176)) %>% mutate(CountryCode = 95, territory1="New Zealand",iso_ter1="NZL", sovereign1="New Zealand", iso_sov1="NZL") %>%
select(CountryCode,lon,lat,territory1,iso_ter1,sovereign1,iso_sov1)
eez_mollweide <- rbind(eez_mollweide,new_zealand_add_v2)
tail(eez_mollweide)
dim(eez_mollweide)
#-- create cell id with country names
cell_id_with_country <- left_join(ocean_coordinates,eez_mollweide,by=c("lon","lat"))
head(cell_id_with_country)
dim(cell_id_with_country)
#-- add Kat's EEZ file
cell_id_with_country_kat_prime <- left_join(cell_id_with_country,ocean_df_with_eezs,by=c("cell_id","lon","lat"))
#add price data with region details, given that region info is included in price info
cell_id_with_country_kat <- left_join(cell_id_with_country_kat_prime,price_country_region_input,by="cell_id")
head(cell_id_with_country_kat)
dim(cell_id_with_country_kat)
#--view regions of the world
#ggplot(data=cell_id_with_country_kat, aes(x=lon, y=lat, color=region.y)) + geom_point()
#Use filter to include only pixels with diving
cell_id_with_country_diving_only <- cell_id_with_country_kat %>% filter(cell_id %in% dives_input$cell_id)
#-- fill out region --- for pixels with missing regions
region_library <- cell_id_with_country_diving_only %>% select(territory1,region.x,region.y) %>% filter(! is.na(territory1)) %>% unique() %>% mutate(region_fill = ifelse(is.na(region.x), region.y, region.x)) %>% select(territory1,region_fill) %>% unique() %>% group_by(territory1) %>% mutate(n=n()) %>% filter(n==1 | !is.na(region_fill)) %>% select(territory1,region_fill)
#region_library <- cell_id_with_country_diving_only %>% select(territory1,region.y) %>% filter(! is.na(territory1)) %>% unique() %>% filter(! is.na(region.y))
#region_library <- rename(region_library, region_fill=region.y)
#-- manual assignment of region for territories/countries with no region assignment
region_library <- region_library %>%
mutate(region_fill=replace(region_fill, territory1=="Alaska", "North America")) %>%
mutate(region_fill=replace(region_fill, territory1=="Albania", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Andaman and Nicobar", "South Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Antarctica", "Latin America & Caribbean")) %>%  #dive pixels nearest to latin america
mutate(region_fill=replace(region_fill, territory1=="Jersey", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Slovenia", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Romania", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Azores", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Lebanon", "Middle East & North Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Madeira", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Canary Islands", "Europe & Central Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Bahrain", "Middle East & North Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Western Sahara", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Hawaii", "East Asia & Pacific")) %>%
mutate(region_fill=replace(region_fill, territory1=="Antigua and Barbuda", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Dominica", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Aruba", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Cameroon", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Galapagos", "Latin America & Caribbean")) %>%
mutate(region_fill=replace(region_fill, territory1=="Chagos Archipelago", "South Asia")) %>%
mutate(region_fill=replace(region_fill, territory1=="Mayotte", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Glorioso Islands", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Réunion", "Sub-Saharan Africa")) %>%
mutate(region_fill=replace(region_fill, territory1=="Easter Island", "East Asia & Pacific"))
head(region_library)
cell_id_with_country_kat_withregion <- left_join(cell_id_with_country_diving_only,region_library, by="territory1")
head(cell_id_with_country_kat_withregion)
dim(cell_id_with_country_kat_withregion)
#check if all is well
ggplot(data=cell_id_with_country_kat_withregion, aes(x=lon, y=lat, color=region_fill)) + geom_point()
#-- PAPER STAT: fraction and absolute size of global ocean suitable for diving
dim(suitability_input) #1814 suitable dive sites
dim(suitability_input)[1]*100/dim(transformed_stockdistrib)[1] #1.21% - fraction of ocean with diving.
dim(suitability_input)[1]*50*50# 4.5 million km - total area of ocean surface with diving
#-- check dives_input
head(dives_input)
dim(dives_input)#1814x4, number of dives and lower and upper bound
sum(dives_input$n_dives_extrap)#33.1 million, average number of dives in the ocean
sum(dives_input$n_dives_extrap_min)#17.1 million lower, lower bound
sum(dives_input$n_dives_extrap_max)#54 million max, upper bound
#-- check price
head(price_constant_input)
cons_price_per_dive <- price_constant_input$price[1]
cons_price_per_dive #constant price per dive of US$58.75
#-- annual revenue in billion US$
sum(dives_input$n_dives_extrap)*cons_price_per_dive/1e9 #1.94B
#lower bound annual revenue
sum(dives_input$n_dives_extrap_min)*cons_price_per_dive/1e9 #1B
#upper bound unnual revenue
sum(dives_input$n_dives_extrap_max)*cons_price_per_dive/1e9 #3.17B
#-- check other prices
head(price_country_region_input)
plot(price_country_region_input$price)
head(price_interpolated_input)
plot(price_interpolated_input$price)
#-- how many species?
#length(unique(MegaData_filtered_step_fin[stocklist,]$SciName))#599 species
MegaData_filtered_step_fin %>% filter(stockid %in% stocklist) %>% select(SciName) %>% unique() %>% dim() #599 species
#-- %K considered
#MegaData_filtered_step_fin[stocklist,] %>% dplyr::summarize(sum(Kfin))/sum(MegaData_PLD_hrange$Kfin) #we will use 74% of the K.
MegaData_filtered_step_fin %>% filter(stockid %in% stocklist) %>% dplyr::summarize(sum(Kfin))/sum(MegaData_PLD_hrange$Kfin) #we will use 74% of the K.
#-- check final list of dataset
#Checkme <- MegaData_filtered_step_fin[stocklist,]
Checkme <- MegaData_filtered_step_fin %>% filter(stockid %in% stocklist)
ggplot(Checkme, aes(x=mean_observed_PLD, y= mean_predicted_PLD)) + geom_point() + geom_abline(slope=1, intercept=0)
# #NOTE-- JUST OPEN THIS WHEN THE DISTANCE MATRICES CHANGE
# #check if we can load individual files here then merge
# #distmat_filenames <- list.files(path=here("data","distance-library","fst_file"), pattern=".fst", all.files=FALSE,full.names=TRUE)
# distmat_filenames <- list.files(path=here("data","distance-library"), pattern=".rds", all.files=FALSE,full.names=TRUE)
# distmat_filenames[1]
# length(distmat_filenames)#40 files
#
# #let us load all the distance matrices, subset, then save as fst file.
# for (i in 1:length(distmat_filenames)){
#   myfile <- readRDS(distmat_filenames[i]) %>% filter(distance<=3667657.8)
#   write.fst(myfile , here("data","distance-library","dist_matrix_subset_fst",paste0(i,"_connect_matrix.fst")))
# }
##-- Connectivity matrix, larvae
#-- no need to run, so we will switch this function off
run_subset_connectivitymatrix <- 0 #1 for turn on, 0 to switch off
#Subset larvae connectivity matrix
if(run_subset_connectivitymatrix == 1){
distmat_filenames_subset_fst <- list.files(path=here("data","distance-library","dist_matrix_subset_fst"), pattern=".fst", all.files=FALSE,full.names=TRUE)
distmat_filenames_subset_fst[1]
length(distmat_filenames_subset_fst)#40 files
source(here("scripts", "functions","func_stitch_connect_matrix.R"))
stocklist2 <- c(461,467,473,475,478,stocklist[393:821])
nstock<-length(stocklist2)
registerDoParallel(6)
#stocklist2 <- 10#stocklist[10:nstock]
#registerDoParallel(detectCores()/2)
foreach(stock_num=stocklist2) %dopar% {
stock_subset_i <- which(transformed_stockdistrib[,stock_num+5] > 0)
##--! this is the code that can be used when the maximum disperal is over 1K km.
distance_mat_full_prop_larvae <- func_stitch_connect_matrix(distmat_files=distmat_filenames_subset_fst,stock_subset_i=stock_subset_i,MegaData_filtered_step2=MegaData_filtered_step2,stock_num=stock_num)
##-- merged_dist_matrix is in km
#distance_mat_full_prop_larvae <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$dispersal_distance_limit[stock_num]) %>% group_by(source) %>% mutate(biom_prop = exp(-( distance^2 / (2*(MegaData_filtered_step2$sigma_larvae[stock_num]^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-distance) %>% as.data.table()
#fts is the fastest in saving and loading files.
fst::write.fst(distance_mat_full_prop_larvae , paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/",stock_num,"_connect_larvae.fst"))
}
doParallel::stopImplicitCluster()
}
# #check how many files
# connect_matrix_nfiles <- list.files(path="/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/", pattern=".fst", all.files=FALSE,full.names=TRUE)
# length(connect_matrix_nfiles)#821 files
# for (i in 1:length(connect_matrix_nfiles)){
#   check<-read.fst(connect_matrix_nfiles[i])
#   print(dim(check)[1])
# }
##check the output
#seeme <- read.fst("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/1_connect_larvae.fst")
#seeme %>% group_by(source) %>% summarize(sum(biom_prop))
#seeme %>% group_by(sink) %>% summarize(sum(biom_prop))
##-- Connectivity matrix, adult
#-- no need to re-run so we will turn this function off
run_subset_connectivitymatrix_adult <- 0 #1 for on, 0 to switch this off
if(run_subset_connectivitymatrix_adult == 1){
registerDoParallel(detectCores()/2)
foreach(stock_num=stocklist) %dopar% {
stock_subset_i <- which(transformed_stockdistrib[,stock_num+5] > 0)
#included here: filter distance
distance_mat_full_prop_adult <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$homerange_radius[stock_num]) %>% group_by(source) %>% mutate(biom_prop = 1/n()) %>% dplyr::select(-distance) %>% as.data.table()
# distance_mat_full_prop <- distance_mat_full %>% filter(pos1 %in% stock_subset_i, pos2 %in% stock_subset_i) %>% group_by(pos1) %>% mutate(biom_prop = exp(-( dist^2 / (2*(sigma^2))) ), biom_prop = biom_prop/sum(biom_prop)) %>% dplyr::select(-dist) %>% as.data.table()
#fts is the fastest in saving and loading files.
fst::write.fst(distance_mat_full_prop_adult , paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix_adult/",stock_num,"_connect_adult.fst"))
}
doParallel::stopImplicitCluster()
}
##--for checking the code
#stock_subset_i <- which(transformed_stockdistrib[,255+5] > 0)
#distance_mat_full_prop_adult <- merged_dist_matrix %>% filter(source %in% stock_subset_i, sink %in% stock_subset_i, distance<=MegaData_filtered_step2$homerange_radius[stock_num]) %>% group_by(source) %>% mutate(biom_prop = 1/n()) %>% dplyr::select(-distance) %>% as.data.table()
#distance_mat_full_prop_adult %>% group_by(source) %>% summarize(sum(biom_prop))
#distance_mat_full_prop_adult %>% group_by(sink) %>% summarize(sum(biom_prop))
#test<-fst::read.fst(paste0("/Users/ren/Documents/GitHub/tourism-mpa-support/connect_matrix/1_connect_larvae.fst"))
#head(test)
##-- Main code that evaluates biomass change for each stock and biodiversity score change
#-- visualize number of dives distribution using histogram with logarithmic scale
ggplot(data.frame(log(dives_input$n_dives_extrap)), aes(log(dives_input$n_dives_extrap))) + geom_histogram(bins=20)
dive_per_country <- left_join(dives_input,cell_id_with_country_kat_withregion,by="cell_id")
iso_library <- dive_per_country %>% select(sovereign1,territory1,iso_sov1,iso_ter1) %>% unique() %>% arrange(sovereign1) %>% filter(!is.na(sovereign1))
#filter CountryCode==NA and try to fill out details
no_info_pixels <- dive_per_country %>% filter(is.na(CountryCode))
no_info_pixels$cell_id #ok, "numeric(0)" means that all pixels have info now (we filled out the 5 pixels with no country info, i.e., New Zealand).
#-- Data Check: check nearest distance to fill out missing pixel info
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[1]-lon)+abs(no_info_pixels$lat[1]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 1 is New Zealand
# #New Zealand Country code is 95
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[2]-lon)+abs(no_info_pixels$lat[2]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 2 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[3]-lon)+abs(no_info_pixels$lat[3]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 3 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[4]-lon)+abs(no_info_pixels$lat[4]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 4 is New Zealand
#
# dive_per_country %>% select(lon,lat,CountryCode,territory1,sovereign1) %>% mutate(distance = sqrt(abs(no_info_pixels$lon[5]-lon)+abs(no_info_pixels$lat[5]-lat))) %>% arrange(distance) %>% head(20)
# #pixel 5 is New Zealand
# --This code is just for verifying that indeed the 5 points are all in New Zealand
# land_shp_moll<-readRDS(file = "/Users/ren/Documents/CODES/FoodProvision/land_shp_moll.rds")
# no_info_pixels %>% ggplot(aes(x=lon,y=lat)) + geom_point(color="red") + #scale_fill_viridis()+#option="plasma")+#scale_fill_gradient(color=viridis)+#scale_fill_gradient(low="white", high="#00539CFF")+#guides(fill=guide_legend())+
#   theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank())+
#   geom_raster()+
#   geom_sf(data = land_shp_moll,fill="darkgray", lwd = 0.1,  inherit.aes = F)
#-- load country classification (SIDS, developing, etc.)
country_classification <- read.csv(here("data","UN_territory_sovereign_classification.csv"))
#country_classification$SIDS <-as.factor(country_classification$Classification)
country_classification_with_iso <- left_join(country_classification,iso_library,by=c("sovereign1","territory1"))
country_classification_kat <- read.csv(here("data","country_status_lookup_manual_category.csv")) %>% mutate(Classification_kat = ifelse(manual_development_status=="Developed", "Developed", "Developing")) %>%
select(iso3,Classification_kat) %>% dplyr::rename(iso_ter1 = iso3)
#-- note from Kat: use "development_status" -- developed and others.
country_classification_with_iso_and_class <- left_join(country_classification_with_iso,country_classification_kat,by="iso_ter1") %>% mutate(match = (Classification==Classification_kat))
#-- plot number of dives per country
head(dive_per_country)
plot_number_dives <- dive_per_country %>% group_by(territory1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap)) %>% left_join(country_classification,by="territory1") %>%
arrange(-n_dive) %>% slice(1:50) %>% ggplot(aes(x = reorder(as.factor(territory1), n_dive/1000000), y = n_dive/1000000, fill=Classification))+
geom_bar(stat = "identity")+ theme_classic()+ coord_flip()+ labs(y = "Dive per year, million")+theme(axis.title.y = element_blank())
plot_number_dives
#-- plot number of dive pixels per country
plot_number_divepexels_country <- dive_per_country %>% group_by(territory1) %>% dplyr::summarize(n_divesites=n()) %>% filter(territory1!="NA") %>% left_join(country_classification,by="territory1") %>%
arrange(-n_divesites) %>% slice(1:50) %>% ggplot(aes(x = reorder(as.factor(territory1), n_divesites), y = n_divesites, fill=Classification))+
geom_bar(stat = "identity")+ theme_classic()+ coord_flip()+ labs(y = "Number of dive site pixel")+theme(axis.title.y = element_blank())
plot_number_divepexels_country
##-- correlate # of dives with on-reef values
ndive_per_sovereign <- dive_per_country %>% group_by(sovereign1,iso_sov1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap))
head(ndive_per_sovereign)
onreef_values <- read.csv(here("data","tourism_reef_values","Tourvalues_Spalding.csv")) %>% group_by(iso_sov1) %>% summarise(onreef_value=sum(OnReef))
head(onreef_values)
correlate_dive_and_value <- merge(x=ndive_per_sovereign,y=onreef_values,by="iso_sov1")
head(correlate_dive_and_value)
plot_correlate_dive_and_value<- ggplot(correlate_dive_and_value, aes(x=onreef_value/1000000,y=n_dive/1000000))+geom_point()+geom_smooth(method = lm,colour="gray")+
geom_text_repel(aes(onreef_value/1000000, n_dive/1000000, label = sovereign1), size = 3)+
labs(x="On-reef tourism value, billion US$", y = "Dive per year, million")+theme_classic()
plot_correlate_dive_and_value
##--correlate # of dives with flikr data
ndive_per_sovereign <- dive_per_country %>% group_by(sovereign1,iso_sov1) %>% dplyr::summarize(n_dive=sum(n_dives_extrap))
head(ndive_per_sovereign)
flickr_data <- read.csv(here("data","flickr","flickr_webscraped_data_raw_v11.csv"))
flickr_data_sum <- flickr_data %>% group_by(iso_code) %>% dplyr::summarize(count=n()) %>% dplyr::rename(iso_sov1=iso_code)
head(flickr_data_sum)
correlate_dive_and_flickr <- merge(x=ndive_per_sovereign,y=flickr_data_sum,by="iso_sov1") %>% filter(is.na(iso_sov1)==F)
head(correlate_dive_and_flickr)
plot_correlate_dive_and_flickr <- ggplot(correlate_dive_and_flickr, aes(x=count,y=n_dive/1000000))+geom_point()+geom_smooth(method = lm,colour="gray")+
geom_text_repel(aes(count, n_dive/1000000, label = sovereign1), size = 3)+
labs(x="Number of flickr photos", y = "Dive per year, million")+theme_classic()
#figure 1 main
figure1<-cowplot::plot_grid(plot_number_divepexels_country, plot_number_dives,plot_correlate_dive_and_value,plot_correlate_dive_and_flickr, ncol = 2, labels = "AUTO",rel_heights=c(1,0.5))
figure1
ggsave(here("figures","main","plot_number_dives.jpg"),figure1, width = 20, height = 20, units = "cm")
#saving a country file for me to assign country development categorization
##---[no need to run] head(dive_per_country)
##---[no need to run] dive_per_country %>% select(sovereign1) %>% unique() %>% write.csv(.,file = here("data","country_classification.csv"))
##---[no need to run] dive_per_country %>% select(territory1) %>% unique() %>% write.csv(.,file = here("data","territory_classification.csv"))
##---[no need to run] dive_per_country %>% select(sovereign1,territory1) %>% unique() %>% arrange(sovereign1) %>% filter(!is.na(sovereign1)) %>% write.csv(.,file = here("data","territory_sovereign_classification.csv"))
##---[no need to run] checkme <- read.csv(here("data","UN_territory_sovereign_classification.csv"))
#prep data to plot the world's dive sites
ocean_coordinates_dive_suitable <- left_join(ocean_coordinates,suitability_input,by="cell_id")
ocean_coordinates_dive_suitable_v2 <- left_join(ocean_coordinates_dive_suitable,dives_input,by="cell_id")
#plot suitability later or current locations of dive sites
world_dive_sites <- ocean_coordinates_dive_suitable_v2 %>% mutate(suitable = replace_na(suitable,0)) %>% ggplot() + geom_raster(aes(x=lon,y=lat,fill=suitable)) + scale_fill_gradientn(colours=c("black","orange")) #ok, great
world_dive_sites
ggsave(here("figures","supplementary","world_dive_sites.jpg"),world_dive_sites, width = 20, height = 12, units = "cm")
#-- MPA location. Assume that a pixel is an MPA is f_highly_mpa>=0.5.
MPA_vec <- transformed_stockdistrib %>% dplyr::select(cell_id,f_highly_mpa) %>% mutate(f_highly_mpa = (f_highly_mpa>=0.5))
MPA_loc <- MPA_vec %>% filter(f_highly_mpa=="TRUE") %>% select(cell_id)
#-- Question: How many of the suitable dive sites are already in MPAs?
divesite_in_MPA <- suitability_input %>% filter(cell_id %in% MPA_loc$cell_id) %>% dim()
dive_cell_id_MPA <- suitability_input %>% filter(cell_id %in% MPA_loc$cell_id) %>% select(cell_id)
divesite_in_MPA#22 pixels out of 1814
divesite_in_MPA[1]*100/dim(dives_input)[1] #1.21% of the dive sites are inside MPA (using 50 x 50km resolution).
##--biodiversity prep
#-- load the functions
# sapply(list.files(pattern = "[.]R$", path = here::here("scripts", "functions"), full.names = TRUE),source)
source(here("scripts", "functions","calculate_relative_bio_benefit.R"))
source(here("scripts", "functions","func_evaluateMPA_explicit.R"))
#-- load data files necessary for biodiversity model
load(file = file.path(this_project_dir,  "data", "02-processed", "model-inputs", "bio_model_input.RData"))
# set Z for biodiversity
z_bio <- 0.25
##---BIODIVERSITY CODE
# Calculate biodiversity benefit from today's protected cells
bio_benefit_current<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_highly_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#Biodiv benefits of zero MPA
MPA_vec$f_zero_mpa<-FALSE
bio_benefit_zero<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_zero_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#Biodiv benefits of 100% ocean in MPA
MPA_vec$f_all_mpa<-TRUE
bio_benefit_all<-calculate_relative_bio_benefit(is_mpa_vect = MPA_vec$f_all_mpa, v_out_matrix =  v_out_matrix,
v_in_matrix = v_in_matrix, weights  = bio_weights,
z_bio = z_bio, bau_benefit = bau_benefit, total_benefit_diff = total_benefit_diff)
#% increase from zero MPA to current MPA
(bio_benefit_current-bio_benefit_zero)*100/bio_benefit_zero
#% increase from current MPA to all MPA
(bio_benefit_all-bio_benefit_current)*100/bio_benefit_current
#biodiversity score, no MPA
bio_benefit_zero/max_benefit_allthreats #0.5326662
#biodiversity score, current MPA
bio_benefit_current/max_benefit_allthreats #0.5445721
#biodiversity score, all MPA
bio_benefit_all/max_benefit_allthreats #0.7563106
#% increase from current MPA to all MPA
(bio_benefit_all-bio_benefit_current)*100/bio_benefit_current
#% increase from current MPA to all threats solved (not needed)
(max_benefit_allthreats-bio_benefit_current)*100/bio_benefit_current
##----- BIOMASS CODE
#--test:
#func_evaluateMPA_explicit(stock_num=1, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc)$biomass
rerun_biomass_code <- 0 #1 for on, 0 to switch this off
if(rerun_biomass_code == 1){
stock_include <- stocklist#c(1,2,4,5,6)#stocklist[8] #c(1,2,4,5,6) #comment this. this is just a placeholder for building our code
ptm <- proc.time()
registerDoParallel(detectCores()/2)
collate_biomass_equi_merged <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA_explicit(stock_num, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc)$biomass
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_biomass_equi_merged)<-MegaData_filtered_step_fin$stockid[stock_include]
dim(collate_biomass_equi_merged)
saveRDS(collate_biomass_equi_merged, file = here("data","collate_biomass_equi_merged.rds"))
}
collate_biomass_equi_merged<-readRDS(file = here("data","collate_biomass_equi_merged.rds"))
##--Calculate B/K per pixel
#compute K per pixel of our stock list
max(transformed_stockdistrib[6:1155],na.rm=T)
min(transformed_stockdistrib[6:1155],na.rm=T)
full_stock_distrib <- transformed_stockdistrib[6:1155]
filtered_stock_distrib <- full_stock_distrib %>% select(c(stocklist))#full_stock_distrib[,stocklist_index] #this is the stock distrib of our filtered stock. Max value is 1 and with NAs
dim(filtered_stock_distrib) #149547 x 813
#K/geogrange
Kmultiplyer <- MegaData_filtered_step_fin %>% select(Kperpixel) %>% slice(stocklist_index) %>% data.frame()
head(Kmultiplyer)
dim(Kmultiplyer)
min(Kmultiplyer)
df_Kmultiplyer <- t(data.frame(rep(Kmultiplyer,each=149547)))
dim(df_Kmultiplyer)
min(df_Kmultiplyer)
#filtered_stock_distrib[is.na(filtered_stock_distrib)] <- 0 #Replace NAs to 0
dim(filtered_stock_distrib) #stock distribution we considered in our model
dim(df_Kmultiplyer)
#check number of pixels per stock
#---rencheck
npixel_per_stock <- colSums(filtered_stock_distrib,na.rm=T)
length(npixel_per_stock)
plot(npixel_per_stock)
min(npixel_per_stock)
#---
#check number of stocks per pixel
#---rencheck
nstock_per_pixel <- rowSums(filtered_stock_distrib,na.rm=T)
length(nstock_per_pixel)
min(nstock_per_pixel)
rencheck <- ocean_coordinates
rencheck$nstock_per_pixel <- nstock_per_pixel
dim(rencheck)
head(rencheck)
rencheck2 <- rencheck %>% filter(cell_id %in% suitability_input$cell_id)
dim(rencheck2)
rencheck2 %>% filter(nstock_per_pixel==0) #oh knows! T15 stocks?
#check other way
dim(full_stock_distrib)
head(full_stock_distrib)
filt <- full_stock_distrib %>% select(c(stocklist))
oi <- rowSums(filt,na.rm=T) #149547
min(oi[suitability_input$cell_id]) #so there are pixels with no biomass because some stocks were removed.
#---
Kdistrib <- filtered_stock_distrib * df_Kmultiplyer#multiply with Kmultiplyer
dim(Kdistrib)
plot(Kdistrib[,1])
#check if the above is correct
filtered_stock_distrib %>% select(`Fis-29732`) %>% filter(!is.na(`Fis-29732`))
Kdistrib %>% select(`Fis-29732`) %>% filter(!is.na(`Fis-29732`)) #ok
TotalKperPixel <- rowSums(Kdistrib,na.rm=T) #colSums to get the K per pixel
#---rencheck
rencheck <- ocean_coordinates
rencheck$TotalKperPixel <- TotalKperPixel
dim(rencheck)
head(rencheck)
rencheck <- rencheck %>% filter(cell_id %in% suitability_input$cell_id)
dim(rencheck)
#---rencheck <- rencheck %>% filter(cell_id %in% dive_cell_id_unprotected)
suitability_input$cell_id
#k per pixel.
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=TotalKperPixel)) + scale_fill_viridis_c() + geom_raster()
#calculate B/K per pixel
BvK <- rowSums(collate_biomass_equi_merged,na.rm = TRUE)/TotalKperPixel
length(BvK)
max(BvK,na.rm=T)
BvK[order(-BvK)]
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK)) + scale_fill_viridis_c(limits = c(0, 1)) + geom_raster() #ok, great
##-----NOW, close all dive pixels and calculate BvK
head(suitability_input)
#change dive sites into MPAs
MPA_vec_dive <- transformed_stockdistrib %>% dplyr::select(cell_id,f_highly_mpa) %>% mutate(f_highly_mpa = (f_highly_mpa>=0.5)) %>% mutate(f_highly_mpa = replace(f_highly_mpa,cell_id %in% suitability_input$cell_id, TRUE))
#this is current MPA + converting all dive sites into MPA.
MPA_loc_dive <- MPA_vec_dive %>% filter(f_highly_mpa=="TRUE") %>% select(cell_id)
rerun_biomass_wMPAdive_code <- 0 #1 for on, 0 to switch this off
if(rerun_biomass_wMPAdive_code == 1){
ptm <- proc.time()
registerDoParallel(detectCores()/2)
collate_biomass_equi_merged_dive <- foreach(stock_num=stock_include, .combine='cbind') %dopar% {
func_evaluateMPA_explicit(stock_num, transformed_stockdistrib,MegaData_filtered_step_fin,MPA_loc_dive)$biomass
}
doParallel::stopImplicitCluster()
(proc.time() - ptm)/60 #check process time in minutes
colnames(collate_biomass_equi_merged_dive) <- MegaData_filtered_step_fin$stockid[stock_include]
saveRDS(collate_biomass_equi_merged_dive, file = here("data","collate_biomass_equi_merged_dive.rds"))
}
collate_biomass_equi_merged_dive <- readRDS(file = here("data","collate_biomass_equi_merged_dive.rds"))
#compute B/K per pixel
BvK_dive <- rowSums(collate_biomass_equi_merged_dive,na.rm = TRUE)/TotalKperPixel
#transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK_dive)) + scale_fill_viridis_c(limits = c(0, 1)) + geom_raster()
transformed_stockdistrib %>% ggplot(aes(x=lon,y=lat,fill=BvK_dive)) + scale_fill_viridis_c() + geom_raster()
